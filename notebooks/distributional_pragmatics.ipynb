{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwDrM-AMtMvq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "# import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.special import logsumexp\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpZXSVOwLXH7"
   },
   "outputs": [],
   "source": [
    "# x: [BATCH w, DIM VECS]: vectors to be projected\n",
    "# m: [DIM VECS, DIM PROJECTION SUBSPACE]. m is a single projection. each column vector in m is a line onto which one projects\n",
    "def get_projection(m):\n",
    "  covariance_matrix = np.dot(np.transpose(m),m)\n",
    "  inverse_covariance_matrix = np.linalg.inv(covariance_matrix)\n",
    "  #inverse_covariance_matrix = [DIM PROJECTION SUBSPACE, DIM PROJECTION SUBSPACE]\n",
    "  \n",
    "  def projection(x):\n",
    "    #x: [DIM VECS, BATCH SIZE]\n",
    "    #[DIM PROJECTION SUBSPACE, BATCH SIZE]\n",
    "    uncorrected_projection_weights = np.dot(np.transpose(m),x.T)\n",
    "    #[DIM PROJECTION SUBSPACE, BATCH SIZE]    \n",
    "    projection_weights = np.dot(inverse_covariance_matrix,uncorrected_projection_weights)\n",
    "    return np.dot(m,projection_weights).T\n",
    "  \n",
    "  return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IHWP_XX8PXi"
   },
   "outputs": [],
   "source": [
    "# def get_literal_listener(prior_mean, sigma1, sigma2):\n",
    "#   #prior_mean: [DIM VECS, 1]\n",
    "#   prior_mean = np.expand_dims(prior_mean,axis=1)\n",
    "#   def literal_listener(u):\n",
    "#     #u: [DIM VECS, UTTERANCE BATCH SIZE]\n",
    "#     posterior_mean = (sigma1*prior_mean + sigma2*u)*(sigma1^2*sigma2^2)/(sigma1^2+sigma2^2)\n",
    "#     return posterior_mean\n",
    "#   return literal_listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fskw3SQoAWXD"
   },
   "outputs": [],
   "source": [
    "# commenting scheme:\n",
    "#   list(A) is a list of variables of type A\n",
    "#   [x,y,z] is an array of shape (x,y,z)\n",
    "  \n",
    "#   DIM VECS = dimension of word embedding space\n",
    "#   BATCH w = number of states w that are batched\n",
    "#   NUM utts = number of utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nxbxynquap9"
   },
   "outputs": [],
   "source": [
    "# class contains several Bayesian pragmatic models:\n",
    "# L0_Unbatched\n",
    "# S1_Batched: fast S1, batched over w, and u (batch of u passed to L0): L0 is implicit in this S1\n",
    "# S1_Unbatched: no batching: useful for understanding the code semantics clearly and for testing the batched version\n",
    "# L1_Unbatched: no batched equivalent written\n",
    "class Pragmatic_Model:\n",
    "  # utterances : list(str). the utterance set U\n",
    "  # projections : list(str). the projection set Q\n",
    "  # vectors : dictionary: key:str,val:[dim vecs] of word embeddings\n",
    "  # sigma1: hyperparameter for L0: variance of L0 prior. See paper\n",
    "  # sigma2: hyperparameter for L0: variance of gaussian used in the semantics\n",
    "  # mu1: hyperparameter for L0: the mean of the L0 prior: e.g. \"man\" in man is a shark. \n",
    "  def __init__(self,\n",
    "              utterances,\n",
    "              projections,\n",
    "              vectors,\n",
    "              sigma1,\n",
    "              sigma2,\n",
    "              mu1):\n",
    "    \n",
    "    self.utterances=utterances\n",
    "    self.projections=projections\n",
    "    # [NUM U, DIM VECS]\n",
    "    self.utterance_vectors = np.asarray([vectors[u] for u in utterances]) \n",
    "    # [NUM Q, DIM VECS, DIM PROJECTION SUBSPACE]\n",
    "    self.projection_vectors = (np.asarray([np.asarray([vectors[word]/np.linalg.norm(vectors[word]) for word in words]).T for words in self.projections]))\n",
    "    self.vectors=vectors\n",
    "    self.sigma1 = sigma1\n",
    "    self.sigma2 = sigma2\n",
    "    self.mu1 = mu1\n",
    "    \n",
    "    self.dimvecs = vectors[\"the\"].shape[0]\n",
    "    # how many dimensions does each projection have?\n",
    "    self.dimsubspace = self.projection_vectors.shape[-1]\n",
    "    \n",
    "  # u : [DIM VECS]\n",
    "  def L0_Unbatched(self,u):\n",
    "    sigma1sq, sigma2sq = self.sigma1 ** 2, self.sigma2 ** 2\n",
    "    mu = np.divide(np.add(self.mu1/sigma1sq, u/sigma2sq),  ((1/sigma1sq) + (1/sigma2sq)))\n",
    "    sigma_base = ((1/sigma1sq) + (1/sigma2sq))**-1\n",
    "    sigma = np.diag([sigma_base] * self.dimvecs)\n",
    "    return mu,sigma\n",
    "  \n",
    "  # w : [1,DIM VECS]\n",
    "  # q : [DIM VECS, DIM PROJECTION SUBSPACE]\n",
    "  def S1_Unbatched(self,w,q):\n",
    "    \n",
    "    projection = get_projection(q)\n",
    "    # calculates a term that decreases with the euclidean distance of q(w) to q(u) where q(x) is x projected onto the subspace spanned by q\n",
    "    def utility(w,projection,u):\n",
    "      l0_posterior_mu, l0_posterior_sigma = self.L0_Unbatched(u=u)\n",
    "      projected_w = projection(w)\n",
    "      projected_l0_posterior_mu = projection(l0_posterior_mu)\n",
    "      log_score = multivariate_normal(projected_l0_posterior_mu,l0_posterior_sigma).logpdf(projected_w)\n",
    "      return log_score\n",
    "    \n",
    "    unnormed_log_probs = [utility(w=w,projection=projection,u=u) for u in self.utterance_vectors]\n",
    "    norm = logsumexp(unnormed_log_probs)\n",
    "    return unnormed_log_probs - norm\n",
    "  \n",
    "  # ws: [BATCH w, DIM VECS]\n",
    "  # q: [DIM VECS, DIM PROJECTION SUBSPACE]\n",
    "  def S1_Batched(self, ws,q):\n",
    "\n",
    "    projection = get_projection(q)\n",
    "\n",
    "    # obtain L0 posterior MU and SIGMA\n",
    "    sigma1sq, sigma2sq = self.sigma1 ** 2, self.sigma2 ** 2\n",
    "    inverse_sd = (1/sigma1sq) + (1/sigma2sq)\n",
    "    sigma = np.diag([1/inverse_sd] * self.dimvecs)\n",
    "    inverse_sigma = np.linalg.inv(sigma)\n",
    "    l0_posterior_mu = np.divide(np.add(self.mu1/sigma1sq, self.utterance_vectors/sigma2sq),inverse_sd)\n",
    "\n",
    "    # projections\n",
    "    # [NUM UTTS, DIM VECS]\n",
    "    projected_l0_posterior_mu = projection(l0_posterior_mu)\n",
    "#     print(\"BATCHED\",projected_l0_posterior_mu)\n",
    "    # [BATCH w, DIM VECS]\n",
    "    projected_ws = projection(ws)\n",
    "    \n",
    "    # compute logprob of gaussian\n",
    "    # [BATCH w, NUM UTTS, DIM VECS]\n",
    "    distances = np.expand_dims(projected_ws,1)-np.expand_dims(projected_l0_posterior_mu,0)\n",
    "    # [BATCH w, NUM UTTS, DIM VECS]\n",
    "    rescaled_distances = np.einsum('ij,abi->abj',np.sqrt(inverse_sigma),distances)\n",
    "    # [BATCH w, NUM UTTS]\n",
    "    unnormed_logprobs = -0.5*np.sum(np.square(rescaled_distances),axis=2)\n",
    "    # [BATCH w,1]\n",
    "    norm = np.expand_dims(logsumexp(unnormed_logprobs,axis=-1),-1)\n",
    "    # [BATCH w, NUM UTTS]\n",
    "    return unnormed_logprobs-norm\n",
    "  \n",
    "  def L1(self,u):\n",
    "    #u: [DIM VECS, 1]\n",
    "    #listener_mean: [DIM VECS, 1]\n",
    "    start = -5\n",
    "    stop = 5.01\n",
    "    step = 0.01\n",
    "    # intervals: [NUM INTERVALS]    \n",
    "    intervals = np.arange(start=start,stop=stop,step=step)\n",
    "    num_intervals = int((stop-start)/step)\n",
    "    \n",
    "    normal = multivariate_normal(mean=self.mu1, cov=[self.sigma1] * self.dimvecs)\n",
    "\n",
    "    \n",
    "    movement = {}\n",
    "    marginal_projection_probs = np.zeros((len(self.projections)))\n",
    "    for i in tqdm(range(len(self.projections))):\n",
    "            \n",
    "      q = self.projection_vectors[i]\n",
    "      # assume q is a vector of unit length\n",
    "      #q: [DIM VECS, 1]\n",
    "      projection = get_projection(q)\n",
    "      # [DIM VECS]\n",
    "      projected_mu1 = projection(self.mu1)\n",
    "      \n",
    "      # [DIM VECS, NUM INTERVALS]\n",
    "      projected_worlds = np.expand_dims(projected_mu1,0) + np.dot(q,np.expand_dims(intervals,0)).T\n",
    "\n",
    "      # [NUM INTERVALS]\n",
    "      speaker_log_likelihood = self.S1_Batched(projected_worlds,q)[:,u]\n",
    "      \n",
    "      # [NUM INTERVALS]\n",
    "      world_log_priors = -1/(self.sigma1**2)*np.square(intervals)\n",
    "      # TODO: draw from real gaussian and see if different\n",
    "#       world_log_priors = np.asarray([normal.logpdf(i) for i in intervals])\n",
    "      \n",
    "      # [NUM INTERVALS]\n",
    "      joint_probs = world_log_priors + speaker_log_likelihood\n",
    "      left,right = np.exp(logsumexp(joint_probs[:num_intervals//2])), np.exp(logsumexp(joint_probs[1+num_intervals//2:]))\n",
    "      movement[i]=right-left\n",
    "      # SCALAR\n",
    "      marginal_projection_prob = logsumexp(joint_probs)      \n",
    "      marginal_projection_probs[i]=marginal_projection_prob\n",
    "    \n",
    "    norm = logsumexp(marginal_projection_probs)\n",
    "    return marginal_projection_probs - norm, movement\n",
    "\n",
    "  def L1_2D(self,u):\n",
    "    #u: [DIM VECS, 1]\n",
    "    #listener_mean: [DIM VECS, 1]\n",
    "    start = -5\n",
    "    stop = 5.1\n",
    "    step = 0.01\n",
    "    # intervals: [NUM INTERVALS]    \n",
    "#     intervals = np.repeat(np.arange(start=start,stop=stop,step=step),self.dimsubspace)\n",
    "#     intervals = intervals.reshape(2,intervals.shape[0]//2)\n",
    "#     intervals = np.expand_dims(np.arange(start=start,stop=stop,step=step),0)\n",
    "    intervals = np.stack([intervals]*self.dimsubspace)\n",
    "    num_intervals = int((stop-start)/step)\n",
    "    \n",
    "    movement = {}\n",
    "    marginal_projection_probs = np.zeros((len(self.projections)))\n",
    "    for i in tqdm(range(len(self.projections))):\n",
    "            \n",
    "      q = self.projection_vectors[i]\n",
    "      # assume q is a vector of unit length\n",
    "      #q: [DIM VECS, 1]\n",
    "      projection = get_projection(q)\n",
    "      # [DIM VECS]\n",
    "      projected_mu1 = projection(self.mu1)\n",
    "      \n",
    "      # [DIM VECS, NUM INTERVALS]\n",
    "#       print(q[:,0,np.newaxis].shape)\n",
    "      x = np.dot(q[:,0,np.newaxis],intervals)\n",
    "      y = np.dot(q[:,1,np.newaxis],intervals)\n",
    "      out = np.transpose([np.tile(x, len(y)), np.repeat(y, len(x))])\n",
    "      print(x.shape,y.shape,out.shape,intervals.shape[1],intervals.shape[1]**2)\n",
    "      print(out)\n",
    "      raise Exception\n",
    "    \n",
    "      projected_worlds = np.expand_dims(projected_mu1,0) + np.dot(q,intervals).T\n",
    "\n",
    "      # [NUM INTERVALS]\n",
    "      speaker_log_likelihood = self.S1_Batched(projected_worlds,q)[:,u]\n",
    "      \n",
    "      # [NUM INTERVALS]\n",
    "      world_log_priors = -1/(self.sigma1**2)*np.square(intervals)\n",
    "      \n",
    "      # [NUM INTERVALS]\n",
    "      joint_probs = world_log_priors + speaker_log_likelihood\n",
    "#       left,right = np.exp(logsumexp(joint_probs[:num_intervals//2])), np.exp(logsumexp(joint_probs[1+num_intervals//2:]))\n",
    "#       movement[i]=right-left\n",
    "      # SCALAR\n",
    "      marginal_projection_prob = logsumexp(joint_probs)      \n",
    "      marginal_projection_probs[i]=marginal_projection_prob\n",
    "     \n",
    "    norm = logsumexp(marginal_projection_probs)\n",
    "    return marginal_projection_probs - norm, movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KfakXGADuxuw"
   },
   "outputs": [],
   "source": [
    "simple_utterances = [\"shark\",\"swimmer\",\"man\"]\n",
    "simple_projections = [[\"swims\",\"vicious\"],[\"vicious\",\"swims\"]]\n",
    "# simple_projections = [[\"swims\"],[\"vicious\"]]\n",
    "\n",
    "simple_vecs = {}\n",
    "simple_vecs[\"swimmer\"]=np.asarray([0.0,1.0])\n",
    "simple_vecs[\"shark\"]=np.asarray([1.0,1.0])\n",
    "simple_vecs[\"man\"]=np.asarray([0.0,0.0])\n",
    "simple_vecs[\"vicious\"]=np.asarray([1.0,0.0])\n",
    "simple_vecs[\"swims\"]=np.asarray([0.0,1.0])\n",
    "simple_vecs[\"the\"]=np.asarray([0.0,0.0])\n",
    "simple_vecs[\"child\"]=np.asarray([0.1,-1.0])\n",
    "simple_vecs[\"nightmare\"]=np.asarray([1.0,1.0])\n",
    "simple_vecs[\"wonder\"]=np.asarray([1.0,-1.0])\n",
    "\n",
    "simple_mu1 = simple_vecs[\"man\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = Pragmatic_Model(utterances=simple_utterances,\n",
    "                                  projections=simple_projections,\n",
    "                                  vectors=simple_vecs,\n",
    "                                 sigma1=5.0,\n",
    "                                 sigma2=0.5,\n",
    "                                 mu1=simple_mu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'intervals' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-621-8c4e0e9b761c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# raw_output, movement = simple_model.L1(u=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mraw_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1_2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-618-2d5e37f7e518>\u001b[0m in \u001b[0;36mL1_2D\u001b[0;34m(self, u)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;31m#     intervals = intervals.reshape(2,intervals.shape[0]//2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;31m#     intervals = np.expand_dims(np.arange(start=start,stop=stop,step=step),0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mintervals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintervals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimsubspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mnum_intervals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'intervals' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# raw_output, movement = simple_model.L1(u=0)\n",
    "raw_output, movement = simple_model.L1_2D(u=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6429603911301341 ['vicious']\n",
      "0.35703960886986585 ['swims']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = sorted(list(zip(np.exp(raw_output),simple_projections)),key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for i,(prob,q) in enumerate(results):\n",
    "    print(prob,q)\n",
    "    if i > 20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZjskIUoKnFL"
   },
   "outputs": [],
   "source": [
    "test_utterances = [\"shark\",\"swimmer\",\"wonder\",\"child\"]\n",
    "test_projections = [[\"swims\"],[\"vicious\"],[\"man\"]]\n",
    "test_mu1 = np.random.rand(5)\n",
    "test_ws = np.random.rand(10,5)\n",
    "\n",
    "test_vecs = {}\n",
    "test_vecs[\"swimmer\"]=np.random.rand(5)\n",
    "test_vecs[\"shark\"]=np.random.rand(5)\n",
    "test_vecs[\"man\"]=np.random.rand(5)\n",
    "test_vecs[\"vicious\"]=np.random.rand(5)\n",
    "test_vecs[\"swims\"]=np.random.rand(5)\n",
    "test_vecs[\"child\"]=np.random.rand(5)\n",
    "test_vecs[\"nightmare\"]=np.random.rand(5)\n",
    "test_vecs[\"wonder\"]=np.random.rand(5)\n",
    "test_vecs[\"the\"]=np.random.rand(5)\n",
    "\n",
    "test_model = Pragmatic_Model(utterances=test_utterances,\n",
    "                                  projections=test_projections,\n",
    "                                  vectors=test_vecs,\n",
    "                                 sigma1=1.0,\n",
    "                                 sigma2=2.0,\n",
    "                                 mu1=test_mu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33373021266959213 ['swims'] -23.495606630748796\n",
      "0.3336409106174595 ['vicious'] -19.856699436855706\n",
      "0.33262887671294833 ['man'] -11.031278492257343\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "lU1yng_ram5U",
    "outputId": "374d19fe-248e-43fc-d89e-b6f1947c163a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.393 -1.379 -1.384 -1.389] [-1.393 -1.379 -1.384 -1.389]\n",
      "[-1.387 -1.385 -1.386 -1.387] [-1.387 -1.385 -1.386 -1.387]\n",
      "[-1.391 -1.381 -1.385 -1.388] [-1.391 -1.381 -1.385 -1.388]\n",
      "[-1.379 -1.394 -1.389 -1.383] [-1.379 -1.394 -1.389 -1.383]\n",
      "[-1.383 -1.391 -1.388 -1.384] [-1.383 -1.391 -1.388 -1.384]\n",
      "[-1.398 -1.373 -1.382 -1.392] [-1.398 -1.373 -1.382 -1.392]\n",
      "[-1.395 -1.376 -1.383 -1.39 ] [-1.395 -1.376 -1.383 -1.39 ]\n",
      "[-1.379 -1.395 -1.389 -1.383] [-1.379 -1.395 -1.389 -1.383]\n",
      "[-1.392 -1.381 -1.384 -1.389] [-1.392 -1.381 -1.384 -1.389]\n",
      "[-1.393 -1.379 -1.384 -1.389] [-1.393 -1.379 -1.384 -1.389]\n"
     ]
    }
   ],
   "source": [
    "#test that S1_Batched and S1_Unbatched are equivalent, up to numerical precision\n",
    "q = test_model.projection_vectors[0]\n",
    "batched = test_model.S1_Batched(ws=test_ws,q=q)\n",
    "\n",
    "for i,w in enumerate(test_ws):\n",
    "  unbatched = test_model.S1_Unbatched(w=test_ws[i],q=q)\n",
    "  b = batched[i]\n",
    "  ub = unbatched\n",
    "  print(b,ub)\n",
    "  assert(np.allclose(b,ub))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "gkCBNHCtdguZ",
    "outputId": "06206ad6-dff5-499c-b441-bc00e0961ab2"
   },
   "outputs": [],
   "source": [
    "# test that batched projection is equivalent to unbatched projection\n",
    "m = np.random.rand(10,3)\n",
    "x = np.random.rand(2,10)\n",
    "\n",
    "projection = get_projection(m)\n",
    "projected_x = projection(x)\n",
    "assert(np.allclose(projection(x)[0],projection(x[0])))\n",
    "assert(np.allclose(projection(x)[1],projection(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickled version of GLoVE\n",
    "vecs = pickle.load(open(\"/Users/reuben/Downloads/glove.840B.plain300\",'rb'))\n",
    "\n",
    "def get_words(with_freqs=False):\n",
    "\tnouns, adjs, words = {},{},set()\n",
    "\twith open('../dist_rsa/data/concreteness.csv', newline='') as csvfile:\n",
    "\t\tr = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "\t\tfor i,row in enumerate(r):\n",
    "\t\t\tif i>0:\n",
    "\t\t\t\tis_bigram = float(row[1])!=0\n",
    "\t\t\t\tis_noun = (row[8])=='Noun'\t\t\n",
    "\t\t\t\tis_adj = (row[8])=='Adjective'\n",
    "\t\t\t\tis_adv = (row[8])=='Adverb'\n",
    "\t\t\t\tfreq = row[7]\n",
    "\t\t\t\tif not is_bigram:\n",
    "\t\t\t\t\tif is_noun:\n",
    "\t\t\t\t\t\tif with_freqs:nouns[row[0]]=float(row[2]),freq\n",
    "\t\t\t\t\t\telse: nouns[row[0]]=float(row[2])\n",
    "\t\t\t\t\tif is_adj:\n",
    "\t\t\t\t\t\tif with_freqs: adjs[row[0]]=float(row[2]),freq\n",
    "\t\t\t\t\t\telse: adjs[row[0]]=float(row[2])\n",
    "\t\treturn nouns,adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZWu1YhQKfFg"
   },
   "outputs": [],
   "source": [
    "abstract_threshold = 2.5\n",
    "concrete_threshold = 3.0\n",
    "\n",
    "target = \"time\"\n",
    "source = \"river\"\n",
    "\n",
    "nouns,adjs = get_words(with_freqs=False)\n",
    "nouns = [noun for noun in nouns if noun in vecs]\n",
    "adjectives = [adjective for adjective in adjectives if adjective in vecs]\n",
    "adjectives = [a for a in adjs if adjs[a] > concrete_threshold and a in vecs]\n",
    "utterances = sorted(nouns,key=lambda x: cosine(vecs[x],vecs[target]))\n",
    "projections = [a for a in adjs if adjs[a] < abstract_threshold and a in vecs]\n",
    "projections = sorted(projections,key=lambda x:cosine(vecs[x],vecs[target]))\n",
    "projections = [[x] for x in projections]\n",
    "\n",
    "if source in utterances: utterances.remove(source)\n",
    "if target in utterances: utterances.remove(target)\n",
    "\n",
    "utterances = [source]+utterances[:100]\n",
    "projections = projections[:100]\n",
    "\n",
    "# projections = [[\"unstable\"],[\"vicious\"]]\n",
    "\n",
    "pragmatic_model = Pragmatic_Model(utterances=utterances,\n",
    "                                  projections=projections,\n",
    "                                  vectors=vecs,\n",
    "                                 sigma1=0.1,\n",
    "                                 sigma2=0.1,\n",
    "                                 mu1=vecs[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_7ZGeIcE4j6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/90 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▏        | 11/90 [00:00<00:00, 107.91it/s]\u001b[A\n",
      " 33%|███▎      | 30/90 [00:00<00:00, 123.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 48/90 [00:00<00:00, 136.22it/s]\u001b[A\n",
      " 77%|███████▋  | 69/90 [00:00<00:00, 151.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 99%|█████████▉| 89/90 [00:00<00:00, 163.61it/s]\u001b[A\n",
      "100%|██████████| 90/90 [00:00<00:00, 175.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n",
      "(101, 50) (50, 2)\n"
     ]
    }
   ],
   "source": [
    "raw_output, movement = pragmatic_model.L1(u=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline [['good', 'supposed'], ['good', 'best'], ['good', 'likely'], ['good', 'difficult'], ['good', 'sure'], ['good', 'able'], ['good', 'prior'], ['good', 'entire'], ['good', 'regular'], ['supposed', 'good']]\n",
      "utterance river\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "60",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-521-d94ca4e04c0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmovement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpragmatic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(movement[pragmatic_model.projections.index([\"pure\"])])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 60"
     ]
    }
   ],
   "source": [
    "print(\"baseline\",projections[:10])\n",
    "print(\"utterance\",pragmatic_model.utterances[0])\n",
    "results = sorted(list(zip(np.exp(raw_output),projections)),key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for i,(prob,q) in enumerate(results):\n",
    "    print(prob,q,movement[pragmatic_model.projections.index(q)])\n",
    "    if i > 20: break\n",
    "# print(movement[pragmatic_model.projections.index([\"pure\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CASE\n",
    "\n",
    "abstract_threshold = 2.5\n",
    "concrete_threshold = 3.0\n",
    "\n",
    "target = \"time\"\n",
    "source = \"river\"\n",
    "\n",
    "nouns,adjs = get_words(with_freqs=False)\n",
    "nouns = [noun for noun in nouns if noun in vecs]\n",
    "adjectives = [adjective for adjective in adjectives if adjective in vecs]\n",
    "adjectives = [a for a in adjs if adjs[a] > concrete_threshold and a in vecs]\n",
    "utterances = sorted(nouns,key=lambda x: cosine(vecs[x],vecs[target]))\n",
    "projections = [a for a in adjs if adjs[a] < abstract_threshold and a in vecs]\n",
    "projections = sorted(projections,key=lambda x:cosine(vecs[x],vecs[target]))\n",
    "# projections = [[x] for x in projections]\n",
    "\n",
    "if source in utterances: utterances.remove(source)\n",
    "if target in utterances: utterances.remove(target)\n",
    "\n",
    "utterances = [source]+utterances[:50]\n",
    "projections = projections[:50]\n",
    "projections = [[x,y] for (x,y) in itertools.product(projections,projections) if x!=y and x>y]\n",
    "\n",
    "pragmatic_model = Pragmatic_Model(utterances=utterances,\n",
    "                                  projections=projections,\n",
    "                                  vectors=vecs,\n",
    "                                 sigma1=0.1,\n",
    "                                 sigma2=0.1,\n",
    "                                 mu1=vecs[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1225 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 5/1225 [00:00<00:27, 44.66it/s]\u001b[A\n",
      "  1%|          | 11/1225 [00:00<00:25, 47.84it/s]\u001b[A\n",
      "  1%|▏         | 16/1225 [00:00<00:25, 48.31it/s]\u001b[A\n",
      "  2%|▏         | 21/1225 [00:00<00:24, 48.69it/s]\u001b[A\n",
      "  2%|▏         | 26/1225 [00:00<00:24, 48.00it/s]\u001b[A\n",
      "  3%|▎         | 32/1225 [00:00<00:23, 49.84it/s]\u001b[A\n",
      "  3%|▎         | 38/1225 [00:00<00:23, 51.09it/s]\u001b[A\n",
      "  4%|▎         | 43/1225 [00:00<00:23, 50.10it/s]\u001b[A\n",
      "  4%|▍         | 48/1225 [00:00<00:23, 49.34it/s]\u001b[A\n",
      "  4%|▍         | 54/1225 [00:01<00:22, 51.90it/s]\u001b[A\n",
      "  5%|▍         | 60/1225 [00:01<00:21, 53.59it/s]\u001b[A\n",
      "  5%|▌         | 66/1225 [00:01<00:24, 47.78it/s]\u001b[A\n",
      "  6%|▌         | 71/1225 [00:01<00:23, 48.24it/s]\u001b[A\n",
      "  6%|▋         | 77/1225 [00:01<00:22, 50.19it/s]\u001b[A\n",
      "  7%|▋         | 83/1225 [00:01<00:21, 52.39it/s]\u001b[A\n",
      "  7%|▋         | 89/1225 [00:01<00:20, 54.26it/s]\u001b[A\n",
      "  8%|▊         | 95/1225 [00:01<00:20, 55.72it/s]\u001b[A\n",
      "  8%|▊         | 101/1225 [00:01<00:20, 55.59it/s]\u001b[A\n",
      "  9%|▊         | 107/1225 [00:02<00:19, 56.59it/s]\u001b[A\n",
      "  9%|▉         | 113/1225 [00:02<00:19, 56.02it/s]\u001b[A\n",
      " 10%|▉         | 119/1225 [00:02<00:20, 54.89it/s]\u001b[A\n",
      " 10%|█         | 125/1225 [00:02<00:19, 56.19it/s]\u001b[A\n",
      " 11%|█         | 131/1225 [00:02<00:19, 56.53it/s]\u001b[A\n",
      " 11%|█         | 137/1225 [00:02<00:20, 54.09it/s]\u001b[A\n",
      " 12%|█▏        | 143/1225 [00:02<00:20, 53.24it/s]\u001b[A\n",
      " 12%|█▏        | 149/1225 [00:02<00:19, 54.92it/s]\u001b[A\n",
      " 13%|█▎        | 155/1225 [00:02<00:20, 52.28it/s]\u001b[A\n",
      " 13%|█▎        | 161/1225 [00:03<00:24, 43.87it/s]\u001b[A\n",
      " 14%|█▎        | 167/1225 [00:03<00:22, 46.97it/s]\u001b[A\n",
      " 14%|█▍        | 172/1225 [00:03<00:24, 43.33it/s]\u001b[A\n",
      " 14%|█▍        | 177/1225 [00:03<00:26, 39.00it/s]\u001b[A\n",
      " 15%|█▍        | 183/1225 [00:03<00:24, 42.63it/s]\u001b[A\n",
      " 15%|█▌        | 189/1225 [00:03<00:22, 45.33it/s]\u001b[A\n",
      " 16%|█▌        | 196/1225 [00:03<00:20, 49.53it/s]\u001b[A\n",
      " 16%|█▋        | 202/1225 [00:03<00:20, 51.01it/s]\u001b[A\n",
      " 17%|█▋        | 208/1225 [00:04<00:19, 52.02it/s]\u001b[A\n",
      " 17%|█▋        | 214/1225 [00:04<00:18, 53.76it/s]\u001b[A\n",
      " 18%|█▊        | 220/1225 [00:04<00:18, 53.52it/s]\u001b[A\n",
      " 18%|█▊        | 226/1225 [00:04<00:18, 53.15it/s]\u001b[A\n",
      " 19%|█▉        | 233/1225 [00:04<00:17, 56.21it/s]\u001b[A\n",
      " 20%|█▉        | 239/1225 [00:04<00:17, 57.14it/s]\u001b[A\n",
      " 20%|██        | 246/1225 [00:04<00:16, 58.70it/s]\u001b[A\n",
      " 21%|██        | 252/1225 [00:04<00:17, 56.84it/s]\u001b[A\n",
      " 21%|██        | 258/1225 [00:04<00:17, 56.75it/s]\u001b[A\n",
      " 22%|██▏       | 264/1225 [00:05<00:16, 56.82it/s]\u001b[A\n",
      " 22%|██▏       | 270/1225 [00:05<00:20, 47.71it/s]\u001b[A\n",
      " 23%|██▎       | 277/1225 [00:05<00:18, 51.14it/s]\u001b[A\n",
      " 23%|██▎       | 283/1225 [00:05<00:20, 46.08it/s]\u001b[A\n",
      " 24%|██▎       | 289/1225 [00:05<00:19, 48.90it/s]\u001b[A\n",
      " 24%|██▍       | 295/1225 [00:05<00:18, 51.07it/s]\u001b[A\n",
      " 25%|██▍       | 301/1225 [00:05<00:17, 53.17it/s]\u001b[A\n",
      " 25%|██▌       | 307/1225 [00:05<00:19, 46.51it/s]\u001b[A\n",
      " 25%|██▌       | 312/1225 [00:06<00:19, 46.36it/s]\u001b[A\n",
      " 26%|██▌       | 318/1225 [00:06<00:18, 49.39it/s]\u001b[A\n",
      " 26%|██▋       | 324/1225 [00:06<00:17, 50.21it/s]\u001b[A\n",
      " 27%|██▋       | 331/1225 [00:06<00:16, 53.24it/s]\u001b[A\n",
      " 28%|██▊       | 338/1225 [00:06<00:15, 55.73it/s]\u001b[A\n",
      " 28%|██▊       | 345/1225 [00:06<00:15, 57.64it/s]\u001b[A\n",
      " 29%|██▊       | 351/1225 [00:06<00:15, 57.35it/s]\u001b[A\n",
      " 29%|██▉       | 358/1225 [00:06<00:14, 58.96it/s]\u001b[A\n",
      " 30%|██▉       | 364/1225 [00:06<00:14, 57.87it/s]\u001b[A\n",
      " 30%|███       | 370/1225 [00:07<00:14, 57.04it/s]\u001b[A\n",
      " 31%|███       | 376/1225 [00:07<00:14, 56.76it/s]\u001b[A\n",
      " 31%|███▏      | 383/1225 [00:07<00:14, 58.02it/s]\u001b[A\n",
      " 32%|███▏      | 389/1225 [00:07<00:16, 52.15it/s]\u001b[A\n",
      " 32%|███▏      | 395/1225 [00:07<00:15, 53.90it/s]\u001b[A\n",
      " 33%|███▎      | 402/1225 [00:07<00:14, 56.44it/s]\u001b[A\n",
      " 33%|███▎      | 408/1225 [00:07<00:14, 57.08it/s]\u001b[A\n",
      " 34%|███▍      | 415/1225 [00:07<00:13, 58.82it/s]\u001b[A\n",
      " 34%|███▍      | 421/1225 [00:07<00:14, 56.84it/s]\u001b[A\n",
      " 35%|███▍      | 427/1225 [00:08<00:16, 49.04it/s]\u001b[A\n",
      " 35%|███▌      | 433/1225 [00:08<00:15, 50.01it/s]\u001b[A\n",
      " 36%|███▌      | 440/1225 [00:08<00:14, 53.10it/s]\u001b[A\n",
      " 36%|███▋      | 447/1225 [00:08<00:13, 55.72it/s]\u001b[A\n",
      " 37%|███▋      | 453/1225 [00:08<00:14, 55.08it/s]\u001b[A\n",
      " 37%|███▋      | 459/1225 [00:08<00:14, 53.40it/s]\u001b[A\n",
      " 38%|███▊      | 465/1225 [00:08<00:16, 44.98it/s]\u001b[A\n",
      " 38%|███▊      | 470/1225 [00:09<00:17, 44.21it/s]\u001b[A\n",
      " 39%|███▉      | 477/1225 [00:09<00:15, 48.09it/s]\u001b[A\n",
      " 39%|███▉      | 483/1225 [00:09<00:15, 48.90it/s]\u001b[A\n",
      " 40%|███▉      | 489/1225 [00:09<00:14, 51.50it/s]\u001b[A\n",
      " 40%|████      | 496/1225 [00:09<00:13, 53.99it/s]\u001b[A\n",
      " 41%|████      | 502/1225 [00:09<00:15, 46.39it/s]\u001b[A\n",
      " 41%|████▏     | 507/1225 [00:09<00:16, 44.06it/s]\u001b[A\n",
      " 42%|████▏     | 512/1225 [00:09<00:17, 39.72it/s]\u001b[A\n",
      " 42%|████▏     | 517/1225 [00:10<00:17, 40.30it/s]\u001b[A\n",
      " 43%|████▎     | 522/1225 [00:10<00:16, 41.50it/s]\u001b[A\n",
      " 43%|████▎     | 527/1225 [00:10<00:16, 41.68it/s]\u001b[A\n",
      " 43%|████▎     | 532/1225 [00:10<00:16, 41.05it/s]\u001b[A\n",
      " 44%|████▍     | 537/1225 [00:10<00:16, 40.90it/s]\u001b[A\n",
      " 44%|████▍     | 542/1225 [00:10<00:17, 38.62it/s]\u001b[A\n",
      " 45%|████▍     | 548/1225 [00:10<00:16, 42.23it/s]\u001b[A\n",
      " 45%|████▌     | 554/1225 [00:10<00:14, 45.01it/s]\u001b[A\n",
      " 46%|████▌     | 559/1225 [00:10<00:14, 45.82it/s]\u001b[A\n",
      " 46%|████▌     | 565/1225 [00:11<00:13, 47.97it/s]\u001b[A\n",
      " 47%|████▋     | 572/1225 [00:11<00:12, 51.56it/s]\u001b[A\n",
      " 47%|████▋     | 578/1225 [00:11<00:13, 47.93it/s]\u001b[A\n",
      " 48%|████▊     | 583/1225 [00:11<00:16, 40.04it/s]\u001b[A\n",
      " 48%|████▊     | 588/1225 [00:11<00:16, 38.57it/s]\u001b[A\n",
      " 48%|████▊     | 593/1225 [00:11<00:16, 39.45it/s]\u001b[A\n",
      " 49%|████▉     | 598/1225 [00:11<00:16, 38.07it/s]\u001b[A\n",
      " 49%|████▉     | 602/1225 [00:12<00:16, 37.93it/s]\u001b[A\n",
      " 49%|████▉     | 606/1225 [00:12<00:16, 37.79it/s]\u001b[A\n",
      " 50%|████▉     | 612/1225 [00:12<00:14, 42.44it/s]\u001b[A\n",
      " 50%|█████     | 617/1225 [00:12<00:15, 39.73it/s]\u001b[A\n",
      " 51%|█████     | 622/1225 [00:12<00:16, 37.47it/s]\u001b[A\n",
      " 51%|█████▏    | 628/1225 [00:12<00:14, 41.43it/s]\u001b[A\n",
      " 52%|█████▏    | 635/1225 [00:12<00:12, 46.40it/s]\u001b[A\n",
      " 52%|█████▏    | 641/1225 [00:12<00:13, 44.54it/s]\u001b[A\n",
      " 53%|█████▎    | 646/1225 [00:13<00:14, 40.76it/s]\u001b[A\n",
      " 53%|█████▎    | 651/1225 [00:13<00:15, 37.34it/s]\u001b[A\n",
      " 53%|█████▎    | 655/1225 [00:13<00:16, 34.63it/s]\u001b[A\n",
      " 54%|█████▍    | 662/1225 [00:13<00:14, 40.02it/s]\u001b[A\n",
      " 54%|█████▍    | 667/1225 [00:13<00:15, 35.40it/s]\u001b[A\n",
      " 55%|█████▍    | 671/1225 [00:13<00:15, 35.82it/s]\u001b[A\n",
      " 55%|█████▌    | 678/1225 [00:13<00:13, 41.09it/s]\u001b[A\n",
      " 56%|█████▌    | 684/1225 [00:13<00:12, 43.37it/s]\u001b[A\n",
      " 56%|█████▌    | 689/1225 [00:14<00:12, 43.97it/s]\u001b[A\n",
      " 57%|█████▋    | 696/1225 [00:14<00:10, 48.31it/s]\u001b[A\n",
      " 57%|█████▋    | 703/1225 [00:14<00:10, 51.88it/s]\u001b[A\n",
      " 58%|█████▊    | 710/1225 [00:14<00:09, 54.69it/s]\u001b[A\n",
      " 58%|█████▊    | 716/1225 [00:14<00:09, 52.86it/s]\u001b[A\n",
      " 59%|█████▉    | 722/1225 [00:14<00:09, 54.80it/s]\u001b[A\n",
      " 59%|█████▉    | 728/1225 [00:14<00:09, 54.94it/s]\u001b[A\n",
      " 60%|█████▉    | 734/1225 [00:14<00:10, 46.82it/s]\u001b[A\n",
      " 60%|██████    | 739/1225 [00:15<00:11, 42.52it/s]\u001b[A\n",
      " 61%|██████    | 745/1225 [00:15<00:10, 44.93it/s]\u001b[A\n",
      " 61%|██████▏   | 751/1225 [00:15<00:09, 48.26it/s]\u001b[A\n",
      " 62%|██████▏   | 757/1225 [00:15<00:10, 43.40it/s]\u001b[A\n",
      " 62%|██████▏   | 762/1225 [00:15<00:11, 41.90it/s]\u001b[A\n",
      " 63%|██████▎   | 768/1225 [00:15<00:10, 45.17it/s]\u001b[A\n",
      " 63%|██████▎   | 774/1225 [00:15<00:09, 47.68it/s]\u001b[A\n",
      " 64%|██████▍   | 781/1225 [00:15<00:08, 51.18it/s]\u001b[A\n",
      " 64%|██████▍   | 787/1225 [00:16<00:08, 52.76it/s]\u001b[A\n",
      " 65%|██████▍   | 793/1225 [00:16<00:08, 53.64it/s]\u001b[A\n",
      " 65%|██████▌   | 799/1225 [00:16<00:08, 53.08it/s]\u001b[A\n",
      " 66%|██████▌   | 805/1225 [00:16<00:07, 53.23it/s]\u001b[A\n",
      " 66%|██████▌   | 811/1225 [00:16<00:07, 54.70it/s]\u001b[A\n",
      " 67%|██████▋   | 817/1225 [00:16<00:07, 53.94it/s]\u001b[A\n",
      " 67%|██████▋   | 823/1225 [00:16<00:07, 54.83it/s]\u001b[A\n",
      " 68%|██████▊   | 829/1225 [00:16<00:07, 53.98it/s]\u001b[A\n",
      " 68%|██████▊   | 835/1225 [00:16<00:07, 53.66it/s]\u001b[A\n",
      " 69%|██████▊   | 842/1225 [00:17<00:06, 55.94it/s]\u001b[A\n",
      " 69%|██████▉   | 848/1225 [00:17<00:06, 57.03it/s]\u001b[A\n",
      " 70%|██████▉   | 854/1225 [00:17<00:06, 57.28it/s]\u001b[A\n",
      " 70%|███████   | 860/1225 [00:17<00:06, 52.64it/s]\u001b[A\n",
      " 71%|███████   | 866/1225 [00:17<00:06, 52.01it/s]\u001b[A\n",
      " 71%|███████   | 872/1225 [00:17<00:07, 48.22it/s]\u001b[A\n",
      " 72%|███████▏  | 877/1225 [00:17<00:08, 41.60it/s]\u001b[A\n",
      " 72%|███████▏  | 882/1225 [00:17<00:09, 36.27it/s]\u001b[A\n",
      " 72%|███████▏  | 886/1225 [00:18<00:09, 36.20it/s]\u001b[A\n",
      " 73%|███████▎  | 892/1225 [00:18<00:08, 40.59it/s]\u001b[A\n",
      " 73%|███████▎  | 897/1225 [00:18<00:08, 37.20it/s]\u001b[A\n",
      " 74%|███████▎  | 901/1225 [00:18<00:09, 35.51it/s]\u001b[A\n",
      " 74%|███████▍  | 905/1225 [00:18<00:08, 36.56it/s]\u001b[A\n",
      " 74%|███████▍  | 910/1225 [00:18<00:08, 37.60it/s]\u001b[A\n",
      " 75%|███████▍  | 914/1225 [00:18<00:09, 33.60it/s]\u001b[A\n",
      " 75%|███████▍  | 918/1225 [00:18<00:08, 34.64it/s]\u001b[A\n",
      " 75%|███████▌  | 924/1225 [00:19<00:07, 38.99it/s]\u001b[A\n",
      " 76%|███████▌  | 929/1225 [00:19<00:07, 41.64it/s]\u001b[A\n",
      " 76%|███████▋  | 935/1225 [00:19<00:06, 45.00it/s]\u001b[A\n",
      " 77%|███████▋  | 941/1225 [00:19<00:05, 47.83it/s]\u001b[A\n",
      " 77%|███████▋  | 947/1225 [00:19<00:05, 50.41it/s]\u001b[A\n",
      " 78%|███████▊  | 953/1225 [00:19<00:05, 52.39it/s]\u001b[A\n",
      " 78%|███████▊  | 959/1225 [00:19<00:04, 53.85it/s]\u001b[A\n",
      " 79%|███████▉  | 965/1225 [00:19<00:04, 54.94it/s]\u001b[A\n",
      " 79%|███████▉  | 971/1225 [00:19<00:04, 54.19it/s]\u001b[A\n",
      " 80%|███████▉  | 977/1225 [00:20<00:04, 53.91it/s]\u001b[A\n",
      " 80%|████████  | 983/1225 [00:20<00:04, 55.11it/s]\u001b[A\n",
      " 81%|████████  | 989/1225 [00:20<00:04, 55.98it/s]\u001b[A\n",
      " 81%|████████  | 995/1225 [00:20<00:04, 55.17it/s]\u001b[A\n",
      " 82%|████████▏ | 1001/1225 [00:20<00:03, 56.24it/s]\u001b[A\n",
      " 82%|████████▏ | 1007/1225 [00:20<00:03, 56.66it/s]\u001b[A\n",
      " 83%|████████▎ | 1013/1225 [00:20<00:03, 55.28it/s]\u001b[A\n",
      " 83%|████████▎ | 1019/1225 [00:20<00:03, 55.70it/s]\u001b[A\n",
      " 84%|████████▎ | 1025/1225 [00:20<00:03, 56.29it/s]\u001b[A\n",
      " 84%|████████▍ | 1031/1225 [00:20<00:03, 56.69it/s]\u001b[A\n",
      " 85%|████████▍ | 1037/1225 [00:21<00:03, 57.10it/s]\u001b[A\n",
      " 85%|████████▌ | 1043/1225 [00:21<00:03, 57.25it/s]\u001b[A\n",
      " 86%|████████▌ | 1049/1225 [00:21<00:03, 56.74it/s]\u001b[A\n",
      " 86%|████████▌ | 1055/1225 [00:21<00:03, 56.43it/s]\u001b[A\n",
      " 87%|████████▋ | 1061/1225 [00:21<00:02, 55.23it/s]\u001b[A\n",
      " 87%|████████▋ | 1067/1225 [00:21<00:02, 55.75it/s]\u001b[A\n",
      " 88%|████████▊ | 1073/1225 [00:21<00:02, 54.24it/s]\u001b[A\n",
      " 88%|████████▊ | 1079/1225 [00:21<00:02, 55.16it/s]\u001b[A\n",
      " 89%|████████▊ | 1085/1225 [00:21<00:02, 55.49it/s]\u001b[A\n",
      " 89%|████████▉ | 1091/1225 [00:22<00:02, 54.31it/s]\u001b[A\n",
      " 90%|████████▉ | 1097/1225 [00:22<00:02, 55.20it/s]\u001b[A\n",
      " 90%|█████████ | 1103/1225 [00:22<00:02, 54.03it/s]\u001b[A\n",
      " 91%|█████████ | 1109/1225 [00:22<00:02, 53.09it/s]\u001b[A\n",
      " 91%|█████████ | 1115/1225 [00:22<00:02, 52.31it/s]\u001b[A\n",
      " 92%|█████████▏| 1121/1225 [00:22<00:01, 52.07it/s]\u001b[A\n",
      " 92%|█████████▏| 1127/1225 [00:22<00:01, 51.43it/s]\u001b[A\n",
      " 92%|█████████▏| 1133/1225 [00:22<00:01, 53.39it/s]\u001b[A\n",
      " 93%|█████████▎| 1139/1225 [00:22<00:01, 54.22it/s]\u001b[A\n",
      " 93%|█████████▎| 1145/1225 [00:23<00:01, 55.65it/s]\u001b[A\n",
      " 94%|█████████▍| 1151/1225 [00:23<00:01, 56.26it/s]\u001b[A\n",
      " 94%|█████████▍| 1157/1225 [00:23<00:01, 53.97it/s]\u001b[A\n",
      " 95%|█████████▍| 1163/1225 [00:23<00:01, 54.16it/s]\u001b[A\n",
      " 95%|█████████▌| 1169/1225 [00:23<00:01, 52.74it/s]\u001b[A\n",
      " 96%|█████████▌| 1175/1225 [00:23<00:00, 51.91it/s]\u001b[A\n",
      " 96%|█████████▋| 1181/1225 [00:23<00:00, 52.74it/s]\u001b[A\n",
      " 97%|█████████▋| 1187/1225 [00:23<00:00, 52.03it/s]\u001b[A\n",
      " 97%|█████████▋| 1193/1225 [00:23<00:00, 51.37it/s]\u001b[A\n",
      " 98%|█████████▊| 1199/1225 [00:24<00:00, 49.39it/s]\u001b[A\n",
      " 98%|█████████▊| 1204/1225 [00:24<00:00, 46.61it/s]\u001b[A\n",
      " 99%|█████████▉| 1210/1225 [00:24<00:00, 48.95it/s]\u001b[A\n",
      " 99%|█████████▉| 1216/1225 [00:24<00:00, 50.74it/s]\u001b[A\n",
      "100%|█████████▉| 1222/1225 [00:24<00:00, 52.55it/s]\u001b[A\n",
      "100%|██████████| 1225/1225 [00:24<00:00, 49.73it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "raw_output, movement = pragmatic_model.L1_2D(u=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline [['good', 'best'], ['good', 'difficult'], ['good', 'able'], ['good', 'entire'], ['good', 'free'], ['good', 'extended'], ['good', 'easy'], ['good', 'different'], ['good', 'bad'], ['good', 'certain']]\n",
      "utterance river\n",
      "0.4382462692175309 ['great', 'entire']\n",
      "0.2641609453667568 ['extended', 'entire']\n",
      "0.18821986855659384 ['great', 'extended']\n",
      "0.031015653111848996 ['major', 'extended']\n",
      "0.029507998835353016 ['major', 'important']\n",
      "0.014861581205509383 ['major', 'great']\n",
      "0.007481177889361597 ['important', 'direct']\n",
      "0.00635096459370982 ['important', 'extended']\n",
      "0.005704300187020967 ['major', 'direct']\n",
      "0.003870983013933641 ['major', 'entire']\n",
      "0.0035785604566456256 ['other', 'important']\n",
      "0.0024493125224575264 ['other', 'direct']\n",
      "0.0008024165114743339 ['other', 'limited']\n",
      "0.0006384590167601447 ['similar', 'particular']\n",
      "0.0005668991933636875 ['similar', 'limited']\n",
      "0.0004235051287421882 ['extended', 'direct']\n",
      "0.00037532891626736474 ['similar', 'other']\n",
      "0.00025388022062583065 ['particular', 'limited']\n",
      "0.0002392082320578664 ['limited', 'direct']\n",
      "0.000164040126852998 ['limited', 'important']\n",
      "0.00013863018255870477 ['great', 'direct']\n",
      "0.00012943741667565393 ['other', 'major']\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline\",projections[:10])\n",
    "print(\"utterance\",pragmatic_model.utterances[0])\n",
    "results = sorted(list(zip(np.exp(raw_output),projections)),key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for i,(prob,q) in enumerate(results):\n",
    "    print(prob,q)\n",
    "    if i > 20: break\n",
    "# print(movement[pragmatic_model.projections.index([\"pure\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BarContainer' object has no attribute 'figure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-0a8fac7dac37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprojs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprojs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BarContainer' object has no attribute 'figure'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "\n",
    "_, projs = list(zip(*results))\n",
    "projs = list(projections)\n",
    "movements = [movement[pragmatic_model.projections.index(i)] for i in projs]\n",
    "projs = [i[0] for i in projs]\n",
    "plt = matplotlib.pyplot.bar(projs, movements)\n",
    "plt.figure(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2147.017405218223,\n",
       " 3495.7439158397683,\n",
       " 2268.1680566728537,\n",
       " 8258.524686373079,\n",
       " 5178.132070887048,\n",
       " 6763.518376771273,\n",
       " 5791.617031160124,\n",
       " 9027.01478738262,\n",
       " 12151.25643154484,\n",
       " 9912.127670659851,\n",
       " 11726.788826559703,\n",
       " 4538.9903182641865,\n",
       " 8067.115409356433,\n",
       " 9179.319019594546,\n",
       " 6451.510168153902,\n",
       " 10114.627502418898,\n",
       " 15395.901346026883,\n",
       " 9621.38724521442,\n",
       " 10346.083914868519,\n",
       " 12335.257010737303,\n",
       " 11974.892323755917,\n",
       " 12685.165559674242,\n",
       " 3253.6420529614697,\n",
       " 12621.295173053542,\n",
       " 15231.509071929235,\n",
       " 11290.065479289016,\n",
       " 14291.341563600363,\n",
       " 11244.201016445408,\n",
       " 9697.508023469793,\n",
       " 15584.965445873942,\n",
       " 14586.96337627311,\n",
       " 13728.945051719846,\n",
       " 12037.96130952477,\n",
       " 7444.991499410389,\n",
       " 9363.678399955104,\n",
       " 8614.058764070462,\n",
       " 16630.712019882463,\n",
       " 17111.21668488429,\n",
       " 16107.75755675892,\n",
       " 17089.843001482965,\n",
       " 10096.354778902496,\n",
       " 8644.217257180455,\n",
       " 11781.347559607635,\n",
       " 9549.090772432115,\n",
       " 15737.385576793095,\n",
       " 17558.445136261875,\n",
       " 14516.548966205006,\n",
       " 16796.344134596304,\n",
       " 13355.526790185504,\n",
       " 15288.508163264512,\n",
       " 18875.958822418554,\n",
       " 9693.899294074392,\n",
       " 20216.62256460488,\n",
       " 16850.90901182612,\n",
       " 12687.221367342234,\n",
       " 19040.100306410717,\n",
       " 18997.0052217816,\n",
       " 13842.33624217656,\n",
       " 11737.114368324037,\n",
       " 15832.044911689201,\n",
       " 17914.989319973152,\n",
       " 16799.115788648676,\n",
       " 20499.614745435,\n",
       " 15603.603463058866,\n",
       " 11146.739006584678,\n",
       " 11254.333792125915,\n",
       " 14459.493469993184,\n",
       " 16559.793580235633,\n",
       " 24456.485586566087,\n",
       " 23308.208492415695,\n",
       " 18607.77693568012,\n",
       " 18975.50681630707,\n",
       " 17254.17052743327,\n",
       " 19681.34220835026,\n",
       " 20907.490460741265,\n",
       " 19520.711077457716,\n",
       " 14860.171527177525,\n",
       " 19717.00419637996,\n",
       " 21025.82510428923,\n",
       " 15198.862513740707,\n",
       " 14229.108226556771,\n",
       " 13946.92841530629,\n",
       " 19955.270671013604,\n",
       " 22287.94770480401,\n",
       " 20774.67427236063,\n",
       " 23195.44466946512,\n",
       " 18169.593722287616,\n",
       " 18492.069318544352,\n",
       " 17928.038007321287,\n",
       " 19136.145694856732,\n",
       " 21303.90120045979,\n",
       " 22597.05872362424,\n",
       " 16072.168282682913,\n",
       " 17806.78722717617,\n",
       " 22039.03766524791,\n",
       " 20628.33471755042,\n",
       " 18082.47340709935,\n",
       " 17521.517620543455,\n",
       " 28885.94826791287,\n",
       " 18084.327444208455]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSkQjO-A40K8"
   },
   "source": [
    "projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.160355464594687"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vector_space_pragmatics.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
