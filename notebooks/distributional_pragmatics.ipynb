{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwDrM-AMtMvq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "# import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.special import logsumexp\n",
    "import csv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert todos: load bert. save dictionary first of bert utterances. quds? nearest adjectives in glove space as per?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpZXSVOwLXH7"
   },
   "outputs": [],
   "source": [
    "# x: [BATCH w, DIM VECS]: vectors to be projected\n",
    "# m: [DIM VECS, DIM PROJECTION SUBSPACE]. m is a single projection. each column vector in m is a line onto which one projects\n",
    "def get_projection(m):\n",
    "  covariance_matrix = np.dot(np.transpose(m),m)\n",
    "  inverse_covariance_matrix = np.linalg.inv(covariance_matrix)\n",
    "  #inverse_covariance_matrix = [DIM PROJECTION SUBSPACE, DIM PROJECTION SUBSPACE]\n",
    "  \n",
    "  def projection(x):\n",
    "    #x: [DIM VECS, BATCH SIZE]\n",
    "    #[DIM PROJECTION SUBSPACE, BATCH SIZE]\n",
    "    uncorrected_projection_weights = np.dot(np.transpose(m),x.T)\n",
    "    #[DIM PROJECTION SUBSPACE, BATCH SIZE]    \n",
    "    projection_weights = np.dot(inverse_covariance_matrix,uncorrected_projection_weights)\n",
    "    return np.dot(m,projection_weights).T\n",
    "  \n",
    "  return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IHWP_XX8PXi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fskw3SQoAWXD"
   },
   "outputs": [],
   "source": [
    "# commenting scheme:\n",
    "#   list(A) is a list of variables of type A\n",
    "#   [x,y,z] is an array of shape (x,y,z)\n",
    "  \n",
    "#   DIM VECS = dimension of word embedding space\n",
    "#   BATCH w = number of states w that are batched\n",
    "#   NUM utts = number of utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nxbxynquap9"
   },
   "outputs": [],
   "source": [
    "# class contains several Bayesian pragmatic models:\n",
    "# L0_Unbatched\n",
    "# S1_Batched: fast S1, batched over w, and u (batch of u passed to L0): L0 is implicit in this S1\n",
    "# S1_Unbatched: no batching: useful for understanding the code semantics clearly and for testing the batched version\n",
    "# L1_Unbatched: no batched equivalent written\n",
    "class Pragmatic_Model:\n",
    "  # utterances : list(str). the utterance set U\n",
    "  # projections : list(str). the projection set Q\n",
    "  # vectors : dictionary: key:str,val:[dim vecs] of word embeddings\n",
    "  # sigma1: hyperparameter for L0: variance of L0 prior. See paper\n",
    "  # sigma2: hyperparameter for L0: variance of gaussian used in the semantics\n",
    "  # mu1: hyperparameter for L0: the mean of the L0 prior: e.g. \"man\" in man is a shark. \n",
    "  def __init__(self,\n",
    "              utterances,\n",
    "              projections,\n",
    "              vectors,\n",
    "              sigma1,\n",
    "              sigma2,\n",
    "              mu1):\n",
    "    \n",
    "    self.utterances=utterances\n",
    "    self.projections=projections\n",
    "    # [NUM U, DIM VECS]\n",
    "    self.utterance_vectors = np.asarray([vectors[u] for u in utterances]) \n",
    "    # [NUM Q, DIM VECS, DIM PROJECTION SUBSPACE]\n",
    "    self.projection_vectors = (np.asarray([np.asarray([vectors[word]/np.linalg.norm(vectors[word]) for word in words]).T for words in self.projections]))\n",
    "    self.vectors=vectors\n",
    "    self.sigma1 = sigma1\n",
    "    self.sigma2 = sigma2\n",
    "    self.mu1 = mu1\n",
    "    \n",
    "    self.dimvecs = vectors[\"the\"].shape[0]\n",
    "    # how many dimensions does each projection have?\n",
    "    self.dimsubspace = self.projection_vectors.shape[-1]\n",
    "    \n",
    "  # u : [DIM VECS]\n",
    "  def L0_Unbatched(self,u):\n",
    "    sigma1sq, sigma2sq = self.sigma1 ** 2, self.sigma2 ** 2\n",
    "    mu = np.divide(np.add(self.mu1/sigma1sq, u/sigma2sq),  ((1/sigma1sq) + (1/sigma2sq)))\n",
    "    sigma_base = ((1/sigma1sq) + (1/sigma2sq))**-1\n",
    "    sigma = np.diag([sigma_base] * self.dimvecs)\n",
    "    return mu,sigma\n",
    "  \n",
    "  # w : [1,DIM VECS]\n",
    "  # q : [DIM VECS, DIM PROJECTION SUBSPACE]\n",
    "  def S1_Unbatched(self,w,q):\n",
    "    \n",
    "    projection = get_projection(q)\n",
    "    # calculates a term that decreases with the euclidean distance of q(w) to q(u) where q(x) is x projected onto the subspace spanned by q\n",
    "    def utility(w,projection,u):\n",
    "      l0_posterior_mu, l0_posterior_sigma = self.L0_Unbatched(u=u)\n",
    "      projected_w = projection(w)\n",
    "      projected_l0_posterior_mu = projection(l0_posterior_mu)\n",
    "      log_score = multivariate_normal(projected_l0_posterior_mu,l0_posterior_sigma).logpdf(projected_w)\n",
    "      return log_score\n",
    "    \n",
    "    unnormed_log_probs = [utility(w=w,projection=projection,u=u) for u in self.utterance_vectors]\n",
    "    norm = logsumexp(unnormed_log_probs)\n",
    "    return unnormed_log_probs - norm\n",
    "  \n",
    "  # ws: [BATCH w, DIM VECS]\n",
    "  # q: [DIM VECS, DIM PROJECTION SUBSPACE]\n",
    "  def S1_Batched(self, ws,q):\n",
    "\n",
    "    projection = get_projection(q)\n",
    "\n",
    "    # obtain L0 posterior MU and SIGMA\n",
    "    sigma1sq, sigma2sq = self.sigma1 ** 2, self.sigma2 ** 2\n",
    "    inverse_sd = (1/sigma1sq) + (1/sigma2sq)\n",
    "    sigma = np.diag([1/inverse_sd] * self.dimvecs)\n",
    "    inverse_sigma = np.linalg.inv(sigma)\n",
    "    l0_posterior_mu = np.divide(np.add(self.mu1/sigma1sq, self.utterance_vectors/sigma2sq),inverse_sd)\n",
    "\n",
    "    # projections\n",
    "    # [NUM UTTS, DIM VECS]\n",
    "    projected_l0_posterior_mu = projection(l0_posterior_mu)\n",
    "#     print(\"BATCHED\",projected_l0_posterior_mu)\n",
    "    # [BATCH w, DIM VECS]\n",
    "    projected_ws = projection(ws)\n",
    "    \n",
    "    # compute logprob of gaussian\n",
    "    # [BATCH w, NUM UTTS, DIM VECS]\n",
    "    distances = np.expand_dims(projected_ws,1)-np.expand_dims(projected_l0_posterior_mu,0)\n",
    "    # [BATCH w, NUM UTTS, DIM VECS]\n",
    "    rescaled_distances = np.einsum('ij,abi->abj',np.sqrt(inverse_sigma),distances)\n",
    "    # [BATCH w, NUM UTTS]\n",
    "    unnormed_logprobs = -0.5*np.sum(np.square(rescaled_distances),axis=2)\n",
    "    # [BATCH w,1]\n",
    "    norm = np.expand_dims(logsumexp(unnormed_logprobs,axis=-1),-1)\n",
    "    # [BATCH w, NUM UTTS]\n",
    "    return unnormed_logprobs-norm\n",
    "  \n",
    "  def L1(self,u):\n",
    "    #u: [DIM VECS, 1]\n",
    "    #listener_mean: [DIM VECS, 1]\n",
    "    start = -5\n",
    "    stop = 5.01\n",
    "    step = 0.1\n",
    "    # intervals: [NUM INTERVALS]    \n",
    "    intervals = np.arange(start=start,stop=stop,step=step)\n",
    "    num_intervals = int((stop-start)/step)\n",
    "    \n",
    "#     normal = multivariate_normal(mean=self.mu1, cov=[self.sigma1] * self.dimvecs)\n",
    "\n",
    "    \n",
    "    movement = {}\n",
    "    marginal_projection_probs = np.zeros((len(self.projections)))\n",
    "    for i in tqdm(range(len(self.projections))):\n",
    "            \n",
    "      q = self.projection_vectors[i]\n",
    "      # assume q is a vector of unit length\n",
    "      #q: [DIM VECS, 1]\n",
    "      projection = get_projection(q)\n",
    "      # [DIM VECS]\n",
    "      projected_mu1 = projection(self.mu1)\n",
    "      \n",
    "      # [DIM VECS, NUM INTERVALS]\n",
    "      projected_worlds = np.expand_dims(projected_mu1,0) + np.dot(q,np.expand_dims(intervals,0)).T\n",
    "\n",
    "      # [NUM INTERVALS]\n",
    "      speaker_log_likelihood = self.S1_Batched(projected_worlds,q)[:,u]\n",
    "      \n",
    "      # [NUM INTERVALS]\n",
    "      world_log_priors = -1/(self.sigma1**2)*np.square(intervals)\n",
    "      # TODO: draw from real gaussian and see if different\n",
    "#       world_log_priors = np.asarray([normal.logpdf(i) for i in intervals])\n",
    "      \n",
    "      # [NUM INTERVALS]\n",
    "      joint_probs = world_log_priors + speaker_log_likelihood\n",
    "      left,right = np.exp(logsumexp(joint_probs[:num_intervals//2])), np.exp(logsumexp(joint_probs[1+num_intervals//2:]))\n",
    "      movement[i]=right-left\n",
    "      # SCALAR\n",
    "      marginal_projection_prob = logsumexp(joint_probs)      \n",
    "      marginal_projection_probs[i]=marginal_projection_prob\n",
    "    \n",
    "    norm = logsumexp(marginal_projection_probs)\n",
    "    return marginal_projection_probs - norm, movement\n",
    "\n",
    "  def L1_2D(self,u):\n",
    "    #u: [DIM VECS, 1]\n",
    "    #listener_mean: [DIM VECS, 1]\n",
    "    start = -5\n",
    "    stop = 5.1\n",
    "    step = 0.5\n",
    "    # intervals: [NUM INTERVALS]    \n",
    "#     intervals = np.repeat(np.arange(start=start,stop=stop,step=step),self.dimsubspace)\n",
    "#     intervals = intervals.reshape(2,intervals.shape[0]//2)\n",
    "#     intervals = np.expand_dims(np.arange(start=start,stop=stop,step=step),0)\n",
    "    intervals = np.arange(start=start,stop=stop,step=step)\n",
    "#     intervals = np.stack([intervals]*self.dimsubspace)\n",
    "    num_intervals = int((stop-start)/step)\n",
    "    \n",
    "    movement = {}\n",
    "    marginal_projection_probs = np.zeros((len(self.projections)))\n",
    "    for i in tqdm(range(len(self.projections))):\n",
    "            \n",
    "      q = self.projection_vectors[i]\n",
    "      # assume q is a vector of unit length\n",
    "      #q: [DIM VECS, 1]\n",
    "      projection = get_projection(q)\n",
    "      # [DIM VECS]\n",
    "      projected_mu1 = projection(self.mu1)\n",
    "      \n",
    "      # [DIM VECS, NUM INTERVALS]\n",
    "#       print(q[:,0,np.newaxis].shape)\n",
    "      q0 = np.dot(q[:,0,np.newaxis],np.expand_dims(intervals,0))\n",
    "      q1 = np.dot(q[:,1,np.newaxis],np.expand_dims(intervals,0))\n",
    "#       q0 = q[:,0]*intervals\n",
    "#       q1 = q[:,1]*intervals\n",
    "      out = np.array([[q0[:,x]+q1[:,y]] for x in range(intervals.shape[0]) for y in range(intervals.shape[0])]).squeeze()\n",
    "#       out = np.transpose([np.tile(x, len(y)), np.rep)eat(y, len(x))])\n",
    "      print(q0.shape,q1.shape,out.shape)\n",
    "#       print(out)\n",
    "#       raise Exception\n",
    "    \n",
    "      projected_worlds = np.expand_dims(projected_mu1,0) + out\n",
    "\n",
    "      # [NUM INTERVALS]\n",
    "      speaker_log_likelihood = self.S1_Batched(projected_worlds,q)[:,u]\n",
    "      \n",
    "      # [NUM INTERVALS]\n",
    "#       print(intervals.shape,np.array([[x,y] for x in intervals for y in intervals]).shape)\n",
    "#       world_log_priors = -1/(self.sigma1**2)*np.square(np.ndarray.flatten(np.array([[x,y] for x in intervals for y in intervals])))\n",
    "      world_log_priors = -1/(self.sigma1**2)*np.square(intervals)\n",
    "      world_log_priors = np.ndarray.flatten(np.dot(np.expand_dims(world_log_priors,1),np.expand_dims(world_log_priors,0)))\n",
    "      print(world_log_priors.shape)\n",
    "      # [NUM INTERVALS]\n",
    "      joint_probs = world_log_priors + speaker_log_likelihood\n",
    "#       left,right = np.exp(logsumexp(joint_probs[:num_intervals//2])), np.exp(logsumexp(joint_probs[1+num_intervals//2:]))\n",
    "#       movement[i]=right-left\n",
    "      # SCALAR\n",
    "      marginal_projection_prob = logsumexp(joint_probs)      \n",
    "      marginal_projection_probs[i]=marginal_projection_prob\n",
    "     \n",
    "    norm = logsumexp(marginal_projection_probs)\n",
    "    return marginal_projection_probs - norm, movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KfakXGADuxuw"
   },
   "outputs": [],
   "source": [
    "simple_utterances = [\"man\",\"shark\",\"swimmer\"]\n",
    "# ,\"wonder\"]\n",
    "simple_projections = [[\"swims\",\"vicious\"],[\"vicious\",\"nightmare\"]]\n",
    "# simple_projections = [[\"swims\"],[\"vicious\"],[\"nightmare\"]]\n",
    "\n",
    "simple_vecs = {}\n",
    "simple_vecs[\"swimmer\"]=np.asarray([0.0,1.0])\n",
    "simple_vecs[\"shark\"]=np.asarray([1.0,1.0])\n",
    "simple_vecs[\"man\"]=np.asarray([0.0,0.0])\n",
    "simple_vecs[\"vicious\"]=np.asarray([1.0,0.0])\n",
    "simple_vecs[\"swims\"]=np.asarray([0.0,1.0])\n",
    "simple_vecs[\"the\"]=np.asarray([0.0,0.0])\n",
    "simple_vecs[\"child\"]=np.asarray([0.1,-1.0])\n",
    "simple_vecs[\"nightmare\"]=np.asarray([1.0,1.0])\n",
    "simple_vecs[\"wonder\"]=np.asarray([1.0,-1.0])\n",
    "\n",
    "simple_mu1 = simple_vecs[\"man\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = Pragmatic_Model(utterances=simple_utterances,\n",
    "                                  projections=simple_projections,\n",
    "                                  vectors=simple_vecs,\n",
    "                                 sigma1=5.0,\n",
    "                                 sigma2=0.5,\n",
    "                                 mu1=simple_mu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 101) (2, 101) (10201, 2)\n",
      "(10201,)\n",
      "(2, 101) (2, 101) (10201, 2)\n",
      "(10201,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# raw_output, movement = simple_model.L1(u=1)\n",
    "raw_output, movement = simple_model.L1_2D(u=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5179756702730719 ['vicious', 'nightmare']\n",
      "0.4820243297269279 ['swims', 'vicious']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = sorted(list(zip(np.exp(raw_output),simple_projections)),key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for i,(prob,q) in enumerate(results):\n",
    "    print(prob,q)\n",
    "    if i > 20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('man', 0.012805862724697095), ('shark', 0.7274222000587304), ('swimmer', 0.25977193721657243)]\n"
     ]
    }
   ],
   "source": [
    "out = simple_model.S1_Batched(np.array([simple_vecs[\"shark\"]]),q=np.array([simple_vecs[\"nightmare\"]]).T).squeeze()\n",
    "print(list(zip(simple_utterances,np.exp(out))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZjskIUoKnFL"
   },
   "outputs": [],
   "source": [
    "test_utterances = [\"shark\",\"swimmer\",\"wonder\",\"child\"]\n",
    "test_projections = [[\"swims\"],[\"vicious\"],[\"man\"]]\n",
    "test_mu1 = np.random.rand(5)\n",
    "test_ws = np.random.rand(10,5)\n",
    "\n",
    "test_vecs = {}\n",
    "test_vecs[\"swimmer\"]=np.random.rand(5)\n",
    "test_vecs[\"shark\"]=np.random.rand(5)\n",
    "test_vecs[\"man\"]=np.random.rand(5)\n",
    "test_vecs[\"vicious\"]=np.random.rand(5)\n",
    "test_vecs[\"swims\"]=np.random.rand(5)\n",
    "test_vecs[\"child\"]=np.random.rand(5)\n",
    "test_vecs[\"nightmare\"]=np.random.rand(5)\n",
    "test_vecs[\"wonder\"]=np.random.rand(5)\n",
    "test_vecs[\"the\"]=np.random.rand(5)\n",
    "\n",
    "test_model = Pragmatic_Model(utterances=test_utterances,\n",
    "                                  projections=test_projections,\n",
    "                                  vectors=test_vecs,\n",
    "                                 sigma1=1.0,\n",
    "                                 sigma2=2.0,\n",
    "                                 mu1=test_mu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33373021266959213 ['swims'] -23.495606630748796\n",
      "0.3336409106174595 ['vicious'] -19.856699436855706\n",
      "0.33262887671294833 ['man'] -11.031278492257343\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "lU1yng_ram5U",
    "outputId": "374d19fe-248e-43fc-d89e-b6f1947c163a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.393 -1.379 -1.384 -1.389] [-1.393 -1.379 -1.384 -1.389]\n",
      "[-1.387 -1.385 -1.386 -1.387] [-1.387 -1.385 -1.386 -1.387]\n",
      "[-1.391 -1.381 -1.385 -1.388] [-1.391 -1.381 -1.385 -1.388]\n",
      "[-1.379 -1.394 -1.389 -1.383] [-1.379 -1.394 -1.389 -1.383]\n",
      "[-1.383 -1.391 -1.388 -1.384] [-1.383 -1.391 -1.388 -1.384]\n",
      "[-1.398 -1.373 -1.382 -1.392] [-1.398 -1.373 -1.382 -1.392]\n",
      "[-1.395 -1.376 -1.383 -1.39 ] [-1.395 -1.376 -1.383 -1.39 ]\n",
      "[-1.379 -1.395 -1.389 -1.383] [-1.379 -1.395 -1.389 -1.383]\n",
      "[-1.392 -1.381 -1.384 -1.389] [-1.392 -1.381 -1.384 -1.389]\n",
      "[-1.393 -1.379 -1.384 -1.389] [-1.393 -1.379 -1.384 -1.389]\n"
     ]
    }
   ],
   "source": [
    "#test that S1_Batched and S1_Unbatched are equivalent, up to numerical precision\n",
    "q = test_model.projection_vectors[0]\n",
    "batched = test_model.S1_Batched(ws=test_ws,q=q)\n",
    "\n",
    "for i,w in enumerate(test_ws):\n",
    "  unbatched = test_model.S1_Unbatched(w=test_ws[i],q=q)\n",
    "  b = batched[i]\n",
    "  ub = unbatched\n",
    "  print(b,ub)\n",
    "  assert(np.allclose(b,ub))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "gkCBNHCtdguZ",
    "outputId": "06206ad6-dff5-499c-b441-bc00e0961ab2"
   },
   "outputs": [],
   "source": [
    "# test that batched projection is equivalent to unbatched projection\n",
    "m = np.random.rand(10,3)\n",
    "x = np.random.rand(2,10)\n",
    "\n",
    "projection = get_projection(m)\n",
    "projected_x = projection(x)\n",
    "assert(np.allclose(projection(x)[0],projection(x[0])))\n",
    "assert(np.allclose(projection(x)[1],projection(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickled version of GLoVE\n",
    "# vecs = pickle.load(open(\"/Users/reuben/Downloads/glove.840B.plain300\",'rb'))\n",
    "vecs = pickle.load(open(\"/Users/reuben/Downloads/glove.twitter.27B.plain25\",'rb'))\n",
    "\n",
    "def get_words(with_freqs=False):\n",
    "\tnouns, adjs, words = {},{},set()\n",
    "\twith open('../dist_rsa/data/concreteness.csv', newline='') as csvfile:\n",
    "\t\tr = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "\t\tfor i,row in enumerate(r):\n",
    "\t\t\tif i>0:\n",
    "\t\t\t\tis_bigram = float(row[1])!=0\n",
    "\t\t\t\tis_noun = (row[8])=='Noun'\t\t\n",
    "\t\t\t\tis_adj = (row[8])=='Adjective'\n",
    "\t\t\t\tis_adv = (row[8])=='Adverb'\n",
    "\t\t\t\tfreq = row[7]\n",
    "\t\t\t\tif not is_bigram:\n",
    "\t\t\t\t\tif is_noun:\n",
    "\t\t\t\t\t\tif with_freqs:nouns[row[0]]=float(row[2]),freq\n",
    "\t\t\t\t\t\telse: nouns[row[0]]=float(row[2])\n",
    "\t\t\t\t\tif is_adj:\n",
    "\t\t\t\t\t\tif with_freqs: adjs[row[0]]=float(row[2]),freq\n",
    "\t\t\t\t\t\telse: adjs[row[0]]=float(row[2])\n",
    "\t\treturn nouns,adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZWu1YhQKfFg"
   },
   "outputs": [],
   "source": [
    "abstract_threshold = 2.5\n",
    "concrete_threshold = 3.0\n",
    "\n",
    "target = \"man\"\n",
    "source = \"shark\"\n",
    "\n",
    "nouns,adjs = get_words(with_freqs=False)\n",
    "nouns = [noun for noun in nouns if noun in vecs]\n",
    "adjectives = [a for a in adjs if adjs[a] > concrete_threshold and a in vecs]\n",
    "utterances = sorted(nouns,key=lambda x: cosine(vecs[x],vecs[target]))\n",
    "projections = [a for a in adjs if adjs[a] < abstract_threshold and a in vecs]\n",
    "projections = sorted(projections,key=lambda x:cosine(vecs[x],vecs[target]))\n",
    "projections = [[x] for x in projections]\n",
    "\n",
    "if source in utterances: utterances.remove(source)\n",
    "if target in utterances: utterances.remove(target)\n",
    "\n",
    "utterances = [source]+utterances[:500]\n",
    "projections = projections[:500]\n",
    "\n",
    "# projections = [[\"unstable\"],[\"vicious\"]]\n",
    "\n",
    "pragmatic_model = Pragmatic_Model(utterances=utterances,\n",
    "                                  projections=projections,\n",
    "                                  vectors=vecs,\n",
    "                                 sigma1=10.0,\n",
    "                                 sigma2=0.1,\n",
    "                                 mu1=vecs[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776715aaf9954f1487c54f9906eaca84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_output, movement = pragmatic_model.L1(u=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline [['bad'], ['glad'], ['sure'], ['damn'], ['sorry'], ['true'], ['crazy'], ['wrong'], ['nice'], ['best']]\n",
      "utterance shark\n",
      "0.18019593030586262 ['normal'] -12.752411518797636\n",
      "0.06630693289388034 ['humble'] -4.692521597889556\n",
      "0.05005289576870094 ['sorry'] -3.5422283037498357\n",
      "0.028125752648599536 ['moral'] -1.9904510131946338\n",
      "0.012885603492530734 ['important'] -0.9119102641546273\n",
      "0.011328387789515972 ['mutual'] -0.80170657956158\n",
      "0.0100766239422366 ['supportive'] -0.7131196304680876\n",
      "0.009636166729778179 ['positive'] -0.6819486066821553\n",
      "0.008230399998731906 ['simple'] -0.5824629200558923\n",
      "0.007318009560224657 ['legal'] -0.5178933245166855\n",
      "0.007148735170450717 ['keen'] -0.5059138271200098\n",
      "0.006198568830310779 ['busy'] -0.43867084244101506\n",
      "0.005989368232884126 ['interested'] -0.4238657793975007\n",
      "0.005950943100232249 ['sensible'] -0.42114644437473203\n",
      "0.005673715984604799 ['honest'] -0.4015271652009474\n",
      "0.0050109038639382765 ['particular'] -0.3546201517737334\n",
      "0.004799850675266956 ['glad'] -0.3396839814078281\n",
      "0.004664164659019002 ['helpful'] -0.3300815230526192\n",
      "0.004490310831563559 ['personal'] -0.3177779402354788\n",
      "0.004478699856863708 ['worthy'] -0.3169562350656921\n",
      "0.004473875264548685 ['ideal'] -0.31661480012591764\n",
      "0.004372665651272492 ['unique'] -0.30945222638762265\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline\",projections[:10])\n",
    "print(\"utterance\",pragmatic_model.utterances[0])\n",
    "results = sorted(list(zip(np.exp(raw_output),projections)),key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for i,(prob,q) in enumerate(results):\n",
    "    print(prob,q,movement[pragmatic_model.projections.index(q)])\n",
    "    if i > 20: break\n",
    "# print(movement[pragmatic_model.projections.index([\"pure\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline [['vanquished'], ['unambiguous'], ['fresh'], ['wild'], ['delicious'], ['plentiful'], ['exotic'], ['good'], ['smaller'], ['nutritious']]\n",
      "utterance shark\n",
      "0.061142378607337296 ['prehistoric'] 0.2679338832992011\n",
      "0.04039511887938222 ['sacramental'] 0.35781296757833664\n",
      "0.03715801237377391 ['dangerous'] -0.3264055251997479\n",
      "0.035779076980152424 ['elusive'] 0.021992331479576174\n",
      "0.027546772540760375 ['spectacular'] -0.24381562439321378\n",
      "0.02672404398927931 ['super'] 0.1272729561475605\n",
      "0.026098184177677668 ['rare'] -0.23106027998616246\n",
      "0.025844215926119376 ['nautical'] -0.22883334214447562\n",
      "0.02424836018076418 ['unfailing'] -0.211182787722992\n",
      "0.02298610424344559 ['crazy'] -0.18722713214998854\n",
      "0.02265762389152906 ['presumptuous'] -0.2006967793741075\n",
      "0.02104449128069598 ['weird'] -0.1771726436770905\n",
      "0.01798012984260194 ['invasive'] -0.1592630552556697\n",
      "0.01752628511092265 ['incredible'] -0.1544080039267802\n",
      "0.01734046469812969 ['damn'] -0.15343062731676177\n",
      "0.01729862431313564 ['homing'] -0.15277175061630652\n",
      "0.016268823777257996 ['impossible'] -0.14402876029392933\n",
      "0.0161150973569621 ['lucky'] -0.1427130383449183\n",
      "0.015485268238110346 ['pristine'] -0.13716582431151061\n",
      "0.015345915095742815 ['strange'] -0.1351921881324957\n",
      "0.013864374469879799 ['serious'] -0.12280800036275766\n",
      "0.013653857121557788 ['bad'] -0.12094342783855622\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline\",projections[:10])\n",
    "print(\"utterance\",pragmatic_model.utterances[0])\n",
    "results = sorted(list(zip(np.exp(raw_output),projections)),key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for i,(prob,q) in enumerate(results):\n",
    "    print(prob,q,movement[pragmatic_model.projections.index(q)])\n",
    "    if i > 20: break\n",
    "# print(movement[pragmatic_model.projections.index([\"pure\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline [['good'], ['wrong'], ['true'], ['strange'], ['lucky'], ['bad'], ['great'], ['guilty'], ['brave'], ['innocent']]\n",
      "utterance shark\n",
      "0.10075042308194951 ['wild'] 0.6744023235258155\n",
      "0.03487957369153994 ['worse'] -0.26408625734087254\n",
      "0.022923285283942687 ['eager'] -0.17356073987973825\n",
      "0.020866933611245156 ['amazing'] -0.1579913346475116\n",
      "0.020435308132146845 ['arrogant'] -0.1547233372159914\n",
      "0.01994421777405727 ['sorry'] -0.151005109010825\n",
      "0.01973209706821721 ['worried'] -0.14939906405725842\n",
      "0.01882532987458157 ['fake'] -0.14221710822119174\n",
      "0.018600195386382988 ['supposed'] -0.14082901439217618\n",
      "0.018427785377330787 ['insane'] -0.1395236339302084\n",
      "0.01790727996099102 ['jealous'] -0.13558269335156362\n",
      "0.017898466967404596 ['dangerous'] -0.13544178313642904\n",
      "0.016985174678854135 ['terrible'] -0.12860109045161633\n",
      "0.015907295099369567 ['silly'] -0.12044006226538201\n",
      "0.015642759087798892 ['obsessed'] -0.1184371612515394\n",
      "0.015591620475810499 ['cruel'] -0.11804997199076445\n",
      "0.015300118118121086 ['weird'] -0.11584289611557368\n",
      "0.015056965324589744 ['ashamed'] -0.11400189849357771\n",
      "0.013357330504801325 ['bizarre'] -0.10113332947801679\n",
      "0.013139078396721316 ['willing'] -0.09948086147452131\n",
      "0.012936011220715698 ['unfortunate'] -0.09794336417096025\n",
      "0.012671443178116517 ['crazy'] -0.09594022087569214\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline\",projections[:10])\n",
    "print(\"utterance\",pragmatic_model.utterances[0])\n",
    "results = sorted(list(zip(np.exp(raw_output),projections)),key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for i,(prob,q) in enumerate(results):\n",
    "    print(prob,q,movement[pragmatic_model.projections.index(q)])\n",
    "    if i > 20: break\n",
    "# print(movement[pragmatic_model.projections.index([\"pure\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_7ZGeIcE4j6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:00<00:33,  1.47it/s]\u001b[A\n",
      "  4%|▍         | 2/50 [00:01<00:32,  1.49it/s]\u001b[A\n",
      "  6%|▌         | 3/50 [00:01<00:30,  1.53it/s]\u001b[A\n",
      "  8%|▊         | 4/50 [00:02<00:29,  1.59it/s]\u001b[A\n",
      " 10%|█         | 5/50 [00:03<00:28,  1.57it/s]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:03<00:29,  1.47it/s]\u001b[A\n",
      " 14%|█▍        | 7/50 [00:04<00:28,  1.51it/s]\u001b[A\n",
      " 16%|█▌        | 8/50 [00:05<00:27,  1.54it/s]\u001b[A\n",
      " 18%|█▊        | 9/50 [00:05<00:26,  1.52it/s]\u001b[A\n",
      " 20%|██        | 10/50 [00:06<00:25,  1.54it/s]\u001b[A\n",
      " 22%|██▏       | 11/50 [00:07<00:25,  1.51it/s]\u001b[A\n",
      " 24%|██▍       | 12/50 [00:07<00:25,  1.50it/s]\u001b[A\n",
      " 26%|██▌       | 13/50 [00:08<00:24,  1.52it/s]\u001b[A\n",
      " 28%|██▊       | 14/50 [00:09<00:24,  1.49it/s]\u001b[A\n",
      " 30%|███       | 15/50 [00:09<00:23,  1.50it/s]\u001b[A\n",
      " 32%|███▏      | 16/50 [00:10<00:25,  1.34it/s]\u001b[A\n",
      " 34%|███▍      | 17/50 [00:11<00:23,  1.38it/s]\u001b[A\n",
      " 36%|███▌      | 18/50 [00:12<00:21,  1.48it/s]\u001b[A\n",
      " 38%|███▊      | 19/50 [00:12<00:21,  1.45it/s]\u001b[A\n",
      " 40%|████      | 20/50 [00:13<00:21,  1.40it/s]\u001b[A\n",
      " 42%|████▏     | 21/50 [00:14<00:20,  1.38it/s]\u001b[A\n",
      " 44%|████▍     | 22/50 [00:14<00:19,  1.45it/s]\u001b[A\n",
      " 46%|████▌     | 23/50 [00:15<00:19,  1.37it/s]\u001b[A\n",
      " 48%|████▊     | 24/50 [00:16<00:18,  1.42it/s]\u001b[A\n",
      " 50%|█████     | 25/50 [00:16<00:17,  1.47it/s]\u001b[A\n",
      " 52%|█████▏    | 26/50 [00:17<00:15,  1.51it/s]\u001b[A\n",
      " 54%|█████▍    | 27/50 [00:18<00:16,  1.37it/s]\u001b[A\n",
      " 56%|█████▌    | 28/50 [00:19<00:16,  1.36it/s]\u001b[A\n",
      " 58%|█████▊    | 29/50 [00:19<00:14,  1.42it/s]\u001b[A\n",
      " 60%|██████    | 30/50 [00:20<00:14,  1.40it/s]\u001b[A\n",
      " 62%|██████▏   | 31/50 [00:21<00:13,  1.39it/s]\u001b[A\n",
      " 64%|██████▍   | 32/50 [00:22<00:12,  1.40it/s]\u001b[A\n",
      " 66%|██████▌   | 33/50 [00:22<00:11,  1.45it/s]\u001b[A\n",
      " 68%|██████▊   | 34/50 [00:23<00:11,  1.42it/s]\u001b[A\n",
      " 70%|███████   | 35/50 [00:24<00:11,  1.33it/s]\u001b[A\n",
      " 72%|███████▏  | 36/50 [00:25<00:10,  1.30it/s]\u001b[A\n",
      " 74%|███████▍  | 37/50 [00:26<00:10,  1.18it/s]\u001b[A\n",
      " 76%|███████▌  | 38/50 [00:26<00:09,  1.24it/s]\u001b[A\n",
      " 78%|███████▊  | 39/50 [00:27<00:08,  1.30it/s]\u001b[A\n",
      " 80%|████████  | 40/50 [00:28<00:07,  1.35it/s]\u001b[A\n",
      " 82%|████████▏ | 41/50 [00:29<00:06,  1.30it/s]\u001b[A\n",
      " 84%|████████▍ | 42/50 [00:29<00:06,  1.31it/s]\u001b[A\n",
      " 86%|████████▌ | 43/50 [00:30<00:05,  1.40it/s]\u001b[A\n",
      " 88%|████████▊ | 44/50 [00:31<00:04,  1.42it/s]\u001b[A\n",
      " 90%|█████████ | 45/50 [00:31<00:03,  1.49it/s]\u001b[A\n",
      " 92%|█████████▏| 46/50 [00:32<00:02,  1.51it/s]\u001b[A\n",
      " 94%|█████████▍| 47/50 [00:32<00:01,  1.58it/s]\u001b[A\n",
      " 96%|█████████▌| 48/50 [00:33<00:01,  1.60it/s]\u001b[A\n",
      " 98%|█████████▊| 49/50 [00:34<00:00,  1.53it/s]\u001b[A\n",
      "100%|██████████| 50/50 [00:34<00:00,  1.54it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "raw_output, movement = pragmatic_model.L1(u=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline [['alternating'], ['astrological'], ['bearish'], ['boastful'], ['consecutive'], ['continental'], ['demographic'], ['disjointed'], ['distinguishable'], ['disturbing']]\n",
      "utterance river\n",
      "0.1560474780865443 ['sullen'] -6.832875473065822\n",
      "0.13340108235415957 ['sleazy'] -5.85769089668664\n",
      "0.10936799893076164 ['matriarchal'] -4.606556682890845\n",
      "0.10261266310513917 ['continental'] 4.505785688711545\n",
      "0.08299353455971968 ['studious'] 3.644297584320696\n",
      "0.07042042467081353 ['disturbing'] -3.0922045298453753\n",
      "0.04142030615907694 ['literate'] -1.8187910947948736\n",
      "0.028364110798092323 ['hardworking'] -1.2454856997141148\n",
      "0.027413246891679705 ['alternating'] 0.43974647249805887\n",
      "0.023936121464454486 ['boastful'] 1.0510499413439234\n",
      "0.017718297002522865 ['womanly'] -0.7775579701678605\n",
      "0.015682312859493498 ['pushy'] -0.6885631442302297\n",
      "0.012379036872685954 ['unattached'] 0.5435711879325296\n",
      "0.011354351638213907 ['visionary'] -0.4919973246401441\n",
      "0.010730180157103343 ['yappy'] 0.4623205324474608\n",
      "0.009620532801915169 ['immaculate'] 0.4224435630545326\n",
      "0.009548050906973292 ['localized'] -0.3814609141292338\n",
      "0.009072685092336405 ['prosperous'] 0.3983767239732453\n",
      "0.008297065009518774 ['nonverbal'] 0.36432927132876153\n",
      "0.007361567952401263 ['quantifiable'] 0.3232391846620983\n",
      "0.0071044661742777435 ['livable'] 0.28251187966478003\n",
      "0.006961686152378065 ['dormant'] -0.2872603243042337\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline\",projections[:10])\n",
    "print(\"utterance\",pragmatic_model.utterances[0])\n",
    "results = sorted(list(zip(np.exp(raw_output),projections)),key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for i,(prob,q) in enumerate(results):\n",
    "    print(prob,q,movement[pragmatic_model.projections.index(q)])\n",
    "    if i > 20: break\n",
    "# print(movement[pragmatic_model.projections.index([\"pure\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CASE\n",
    "\n",
    "abstract_threshold = 2.5\n",
    "concrete_threshold = 3.0\n",
    "\n",
    "target = \"man\"\n",
    "source = \"shark\"\n",
    "\n",
    "nouns,adjs = get_words(with_freqs=False)\n",
    "nouns = [noun for noun in nouns if noun in vecs]\n",
    "adjectives = [adjective for adjective in adjectives if adjective in vecs]\n",
    "adjectives = [a for a in adjs if adjs[a] > concrete_threshold and a in vecs]\n",
    "utterances = sorted(nouns,key=lambda x: cosine(vecs[x],vecs[target]))\n",
    "projections = [a for a in adjs if adjs[a] < abstract_threshold and a in vecs]\n",
    "projections = sorted(projections,key=lambda x:cosine(vecs[x],vecs[target]))\n",
    "# projections = [[x] for x in projections]\n",
    "\n",
    "if source in utterances: utterances.remove(source)\n",
    "if target in utterances: utterances.remove(target)\n",
    "\n",
    "utterances = [source]+utterances[:50]\n",
    "projections = projections[:10]\n",
    "projections = [[x,y] for (x,y) in itertools.product(projections,projections) if x!=y and x>y]\n",
    "\n",
    "pragmatic_model = Pragmatic_Model(utterances=utterances,\n",
    "                                  projections=projections,\n",
    "                                  vectors=vecs,\n",
    "                                 sigma1=1.0,\n",
    "                                 sigma2=0.1,\n",
    "                                 mu1=vecs[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/45 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/45 [00:02<02:11,  2.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 2/45 [00:05<02:08,  2.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 3/45 [00:08<02:01,  2.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 4/45 [00:11<01:55,  2.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 5/45 [00:13<01:50,  2.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 6/45 [00:17<01:51,  2.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 7/45 [00:20<01:55,  3.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 8/45 [00:23<01:55,  3.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 9/45 [00:27<02:02,  3.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 10/45 [00:32<02:14,  3.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 11/45 [00:36<02:12,  3.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 12/45 [00:43<02:41,  4.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 13/45 [00:47<02:25,  4.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 14/45 [00:50<02:06,  4.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 15/45 [00:54<01:57,  3.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▌      | 16/45 [00:57<01:47,  3.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 17/45 [01:00<01:41,  3.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 18/45 [01:03<01:33,  3.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 19/45 [01:07<01:27,  3.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 20/45 [01:10<01:22,  3.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 21/45 [01:13<01:16,  3.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▉     | 22/45 [01:15<01:09,  3.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 23/45 [01:18<01:04,  2.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 24/45 [01:21<00:59,  2.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 25/45 [01:23<00:54,  2.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 26/45 [01:26<00:50,  2.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 27/45 [01:28<00:46,  2.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 28/45 [01:31<00:44,  2.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|██████▍   | 29/45 [01:34<00:43,  2.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 30/45 [01:36<00:39,  2.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|██████▉   | 31/45 [01:39<00:36,  2.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 32/45 [01:41<00:33,  2.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████▎  | 33/45 [01:44<00:30,  2.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 34/45 [01:46<00:27,  2.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 35/45 [01:49<00:25,  2.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 36/45 [01:52<00:23,  2.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 37/45 [01:54<00:20,  2.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 38/45 [01:56<00:17,  2.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 39/45 [01:59<00:14,  2.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 40/45 [02:01<00:12,  2.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|█████████ | 41/45 [02:04<00:10,  2.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 42/45 [02:07<00:07,  2.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|█████████▌| 43/45 [02:09<00:04,  2.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 44/45 [02:12<00:02,  2.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n",
      "(300, 21) (300, 21) (441, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 45/45 [02:15<00:00,  2.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441,)\n"
     ]
    }
   ],
   "source": [
    "raw_output, movement = pragmatic_model.L1_2D(u=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline [['good', 'bad'], ['good', 'brave'], ['wrong', 'good'], ['wrong', 'true'], ['wrong', 'strange'], ['wrong', 'lucky'], ['wrong', 'bad'], ['wrong', 'great'], ['wrong', 'guilty'], ['wrong', 'brave']]\n",
      "utterance shark\n",
      "0.039643934271529874 ['good', 'brave']\n",
      "0.039643934271529874 ['wrong', 'good']\n",
      "0.039643934271529874 ['wrong', 'strange']\n",
      "0.039643934271529874 ['wrong', 'guilty']\n",
      "0.039643934271529874 ['wrong', 'brave']\n",
      "0.039643934271529874 ['wrong', 'innocent']\n",
      "0.039643934271529874 ['true', 'guilty']\n",
      "0.039643934271529874 ['true', 'brave']\n",
      "0.039643934271529874 ['true', 'innocent']\n",
      "0.039643934271529874 ['strange', 'guilty']\n",
      "0.039643934271529874 ['strange', 'innocent']\n",
      "0.039643934271529874 ['lucky', 'innocent']\n",
      "0.039643934271529874 ['great', 'brave']\n",
      "0.039643934271529874 ['guilty', 'good']\n",
      "0.039643934271529874 ['guilty', 'bad']\n",
      "0.039643934271529874 ['guilty', 'great']\n",
      "0.039643934271529874 ['brave', 'bad']\n",
      "0.039643934271529874 ['innocent', 'good']\n",
      "0.039643934271529874 ['innocent', 'bad']\n",
      "0.039643934271529874 ['innocent', 'great']\n",
      "0.039643934271529874 ['innocent', 'guilty']\n",
      "0.039643934271529874 ['innocent', 'brave']\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline\",projections[:10])\n",
    "print(\"utterance\",pragmatic_model.utterances[0])\n",
    "results = sorted(list(zip(np.exp(raw_output),projections)),key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for i,(prob,q) in enumerate(results):\n",
    "    print(prob,q)\n",
    "    if i > 20: break\n",
    "# print(movement[pragmatic_model.projections.index([\"pure\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BarContainer' object has no attribute 'figure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-0a8fac7dac37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprojs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprojs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BarContainer' object has no attribute 'figure'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHXtJREFUeJzt3X+QXlWd5/H3h/BbhCBEJyQ4YanMKOPOROxFRme3WHUw4O6As1gDzkpUZqMCKqNbZbBqCvw1o1WLVuEPZuOQJbiOgUWnSEkcJrLEGVcFGgk/AiIt8iOTCMHw0yAh6e/+cc61T9/cp7tv99PdT3d/XlVP9X3OPffec+5z7/3ec859nlZEYGZmNlb7TXcBzMxsZnHgMDOzVhw4zMysFQcOMzNrxYHDzMxaceAwM7NWHDjMzKwVBw4zM2tl1MAh6WBJt0q6U9IWSZ/I6cdJukXSA5KukXRgTj8ovx/I85cU67o4p98v6a1F+vKcNiBpVferaWZm3aLRvjkuScBLIuI5SQcA3wc+DHwE+FZErJP0t8CdEXGFpPOB34+I90s6G3h7RPyZpBOAbwAnAccA3wV+J2/mp8AfA1uB24BzIuLekcp19NFHx5IlS8ZXazOzOer2229/IiIWTGQd+4+WIVJkeS6/PSC/AngT8M6cvha4FLgCOCNPA1wHfCkHnzOAdRHxAvBzSQOkIAIwEBEPAkhal/OOGDiWLFlCf3//6DU0M7PfkPTwRNcxpjEOSfMkbQYeBzYCPwOeiog9OctWYFGeXgQ8CpDnPw0cVabXlumUbmZmPWhMgSMi9kbEMmAxqZXw6qZs+a86zGubvg9JKyX1S+rfsWPH6AU3M7Oua/VUVUQ8BWwCTgbmS6q6uhYD2/L0VuBYgDz/CGBnmV5bplN60/ZXR0RfRPQtWDChLjozMxunsTxVtUDS/Dx9CPAW4D7gZuCsnG0FcH2eXp/fk+f/3zxOsh44Oz91dRywFLiVNBi+ND+ldSBwds5rZmY9aNTBcWAhsFbSPFKguTYivi3pXmCdpE8DdwBX5vxXAl/Lg987SYGAiNgi6VrSoPce4IKI2Asg6ULgRmAesCYitnSthmZm1lWjPo7bq/r6+sJPVZmZtSPp9ojom8g6/M1xMzNrxYHDzMxaceAwM7NWHDhsxliy6gaWrLphuothNuc5cJiZWSsOHGZm1ooDh5mZteLAYWZmrThwmJlZKw4cZmbWigOHmZm14sBhZmatOHCYmVkrDhxmZtaKA4eZmbXiwGFmZq04cJiZWSsOHGZm1ooDh5mZteLAYWZmrThwmJlZKw4cZmbWigOHmZm14sBhZmatOHCYmVkrDhxmZtaKA4eZmbUyauCQdKykmyXdJ2mLpA/n9Esl/aukzfl1erHMxZIGJN0v6a1F+vKcNiBpVZF+nKRbJD0g6RpJB3a7omZm1h1jaXHsAT4aEa8GTgYukHRCnveFiFiWXxsA8ryzgd8DlgNfkTRP0jzgy8BpwAnAOcV6PpfXtRR4EjivS/UzM7MuGzVwRMT2iPhxnn4WuA9YNMIiZwDrIuKFiPg5MACclF8DEfFgROwG1gFnSBLwJuC6vPxa4MzxVsjMzCZXqzEOSUuA1wK35KQLJd0laY2kI3PaIuDRYrGtOa1T+lHAUxGxp5ZuZmY9aMyBQ9JhwDeBiyLiGeAK4HhgGbAduKzK2rB4jCO9qQwrJfVL6t+xY8dYi25mZl00psAh6QBS0Ph6RHwLICIei4i9ETEIfJXUFQWpxXBssfhiYNsI6U8A8yXtX0vfR0Ssjoi+iOhbsGDBWIpuZmZdNpanqgRcCdwXEZ8v0hcW2d4O3JOn1wNnSzpI0nHAUuBW4DZgaX6C6kDSAPr6iAjgZuCsvPwK4PqJVcvMzCbL/qNn4Y3Au4C7JW3OaR8nPRW1jNSt9BDwPoCI2CLpWuBe0hNZF0TEXgBJFwI3AvOANRGxJa/vY8A6SZ8G7iAFKjOb45asugGAhz77tmkuiZVGDRwR8X2axyE2jLDMZ4DPNKRvaFouIh5kqKvLzMx6mL85bmZmrThwmJlZKw4cZmbWigOHmZm14sBhZmatOHCYmVkrDhxmZtbKWL4AaNYV1Ze5wF/oMpvJ3OIws1lpyaobht2sWPc4cJiZWSsOHGZm1ooDh5mZteLAYT3HfdNmvc2Bw8zMWnHgsBnPLRSzqeXAYWZmrczJwOE7VDOz8ZuTgcPMzMbPgcPMzFpx4DAzs1YcOMzMrBX/Oq614l+4NTO3OMzMrBW3OMzmMLcgbTzc4jCzGcffxZpeDhw9yCeFmfUyBw6zWcQ3HTYVRg0cko6VdLOk+yRtkfThnP4ySRslPZD/HpnTJelySQOS7pJ0YrGuFTn/A5JWFOmvk3R3XuZySZqMyprNFg4QNp3G0uLYA3w0Il4NnAxcIOkEYBVwU0QsBW7K7wFOA5bm10rgCkiBBrgEeD1wEnBJFWxynpXFcssnXjUzM5sMoz5VFRHbge15+llJ9wGLgDOAU3K2tcAm4GM5/eqICOBHkuZLWpjzboyInQCSNgLLJW0CDo+IH+b0q4Ezge90p4pmZt03l59IazXGIWkJ8FrgFuAVOahUweXlOdsi4NFisa05baT0rQ3pTdtfKalfUv+OHTvaFN3MzLpkzN/jkHQY8E3gooh4ZoRhiKYZMY70fRMjVgOrAfr6+hrzzBRz+W7FzGa2MQUOSQeQgsbXI+JbOfkxSQsjYnvuino8p28Fji0WXwxsy+mn1NI35fTFDflnLAcFM5vNxvJUlYArgfsi4vPFrPVA9WTUCuD6Iv3c/HTVycDTuSvrRuBUSUfmQfFTgRvzvGclnZy3dW6xLrMZp3riyU892Ww1lhbHG4F3AXdL2pzTPg58FrhW0nnAI8A78rwNwOnAALALeA9AROyU9Cngtpzvk9VAOfAB4CrgENKguAfGbUTVRdktOrOpN5anqr5P8zgEwJsb8gdwQYd1rQHWNKT3A68ZrSxmZjb9/M1xMzNrxb+OO4Xc522zlR8ImVscOKwrZuqFw2MlU8v7e3ZwV5WZmbXiFoeNyl1sZlZy4DDLZmp3m9lUc1eVmZm14sBhZmatuKtqDKazC6OXn0Lx2IfZ3OTA0dJc6Qd3UDCzThw4JpkvwGY223iMw8zMWnGLYwLmSreV2Wzi83bi3OIwM7NWHDhmGf8DITObbA4cZj1mrgT/uVLP2ciBw8zMWnHgmCPm4t3dXKyzzUwz7Vh14DAzs1b8OK6Z7aMXH1nt5Z/fmWvc4jAzs1YcOMzMrBUHDrMeNtMGTW1u8BhHl/jkNrO5woHDzADf/NjYuavKzGYNd+1NDQcOs2nii1wz75feN2rgkLRG0uOS7inSLpX0r5I259fpxbyLJQ1Iul/SW4v05TltQNKqIv04SbdIekDSNZIO7GYFzWz6VEHAgWB2GUuL4ypgeUP6FyJiWX5tAJB0AnA28Ht5ma9ImidpHvBl4DTgBOCcnBfgc3ldS4EngfMmUiEzs141W4LoqIEjIv4Z2DnG9Z0BrIuIFyLi58AAcFJ+DUTEgxGxG1gHnCFJwJuA6/Lya4EzW9aha2bLh2pW52PbumkiYxwXSrord2UdmdMWAY8WebbmtE7pRwFPRcSeWnojSSsl9Uvq37FjxwSKbmZm4zXex3GvAD4FRP57GfBeQA15g+YAFSPkbxQRq4HVAH19fR3zdYPvzszMmo0rcETEY9W0pK8C385vtwLHFlkXA9vydFP6E8B8SfvnVkeZ38zMetC4uqokLSzevh2onrhaD5wt6SBJxwFLgVuB24Cl+QmqA0kD6OsjIoCbgbPy8iuA68dTJrOxcn+/2cSM2uKQ9A3gFOBoSVuBS4BTJC0jdSs9BLwPICK2SLoWuBfYA1wQEXvzei4EbgTmAWsiYkvexMeAdZI+DdwBXNm12s0y/lnp3tKLPz1uNhVGDRwRcU5DcseLe0R8BvhMQ/oGYEND+oOkp65sjnEgNJuZ5vw3x91tYWbWzpwPHGZm1o4DR49wy8fMZgr/rPoM5fGBmcED6DYbucVhZmatOHCYmVkr7qoyG4W7m8yGc4vDzMxaceAwM7NWHDjMzKwVBw4zM2vFg+NzkL8DYrNJLxzPc+0BCrc4zMysFbc4bFL5Z1TMZh+3OMzMrBUHDrMpNJU/ZukfzrTJ4sBhZrOeg2h3eYzDrAVffMwcOMzM9tHp8VrfOCTuqjIzs1YcOMzMrBUHjjlutg0adqrPbKun2XRy4JgFfFE0s6nkwGFmZq04cJiZWSsOHGZm1sqogUPSGkmPS7qnSHuZpI2SHsh/j8zpknS5pAFJd0k6sVhmRc7/gKQVRfrrJN2dl7lckrpdSTMz656xtDiuApbX0lYBN0XEUuCm/B7gNGBpfq0EroAUaIBLgNcDJwGXVMEm51lZLFfflpmZ9ZBRvzkeEf8saUkt+QzglDy9FtgEfCynXx0RAfxI0nxJC3PejRGxE0DSRmC5pE3A4RHxw5x+NXAm8J2JVMrMrC0/mTh24/3JkVdExHaAiNgu6eU5fRHwaJFva04bKX1rQ7rZnNIL/8WuW3wBnv26PTjeND4R40hvXrm0UlK/pP4dO3aMs4hmZjYR421xPCZpYW5tLAQez+lbgWOLfIuBbTn9lFr6ppy+uCF/o4hYDawG6Ovr6xhgzGzyuWUxd403cKwHVgCfzX+vL9IvlLSONBD+dA4uNwJ/XQyInwpcHBE7JT0r6WTgFuBc4IvjLJPNYLOpq8ZmFwfIfY0aOCR9g9RaOFrSVtLTUZ8FrpV0HvAI8I6cfQNwOjAA7ALeA5ADxKeA23K+T1YD5cAHSE9uHUIaFPfAuNkcM103Dg4K4zOWp6rO6TDrzQ15A7igw3rWAGsa0vuB14xWDjMz6w3+R07Wdb6LM5vdHDjMusDB0uYS/1aVmVkPmQn/JsGBw8zMWnHgMDOzVjzGYb/Ri81jf7/DrPe4xWFmZq04cJiZWSsOHGZmPapXn7By4DAzm0S9evGfCAcOMzNrxYHDzMxaceAwM7NWHDjM5pjZ2OduU8uBw8zMWnHgMDOzVhw4zMysFQcOMzNrxYHDbIbwoLb1CgcOMzNrxYHDzMxa8f/jMLMRld1j/r8oBm5xmJlZSw4cZmbWigOHmZm14jEOswZ+7NWsM7c4zMyslQkFDkkPSbpb0mZJ/TntZZI2Snog/z0yp0vS5ZIGJN0l6cRiPSty/gckrZhYlczMbDJ1o8XxHyNiWUT05fergJsiYilwU34PcBqwNL9WAldACjTAJcDrgZOAS6pgY2ZmvWcyuqrOANbm6bXAmUX61ZH8CJgvaSHwVmBjROyMiCeBjcDySSiXmZl1wUQDRwD/JOl2SStz2isiYjtA/vvynL4IeLRYdmtO65RuZjZrzeTfHpvoU1VvjIhtkl4ObJT0kxHyqiEtRkjfdwUpOK0EeOUrX9m2rGZm1gUTanFExLb893HgH0hjFI/lLijy38dz9q3AscXii4FtI6Q3bW91RPRFRN+CBQsmUnQzMxuncQcOSS+R9NJqGjgVuAdYD1RPRq0Ars/T64Fz89NVJwNP566sG4FTJR2ZB8VPzWlmZtaDJtJV9QrgHyRV6/n7iPhHSbcB10o6D3gEeEfOvwE4HRgAdgHvAYiInZI+BdyW830yInZOoFxmc0rVT+4fILSpMu7AEREPAn/QkP5L4M0N6QFc0GFda4A14y2LmZlNHX9z3MzMWnHgMDOzVhw4zMysFQcOMzNrxYHDzMxaceAwM7NW/I+czGzMZupvK1l3ucUxi83kH1Ezs97lwGFmZq04cJiZWSsOHGZm1ooDh5mZteLAYWZmrThwmJlZKw4cZmbWir8AaGbWReV3p7r5z7V66R92ucVhZmatOHCYmVkrDhxmZtaKA4eZmbXiwGFmZq04cJiZWSsOHGZm1ooDh5mZteLAYWZmrThwmJlZKw4cZmbWSs8EDknLJd0vaUDSqukuj5mZNeuJwCFpHvBl4DTgBOAcSSdMb6nMzKxJTwQO4CRgICIejIjdwDrgjGkuk5mZNeiVwLEIeLR4vzWnmZlZj1FETHcZkPQO4K0R8Rf5/buAkyLig7V8K4GV+e3vAvdPYLNHA09M4vRUbKPXpnulHK6z6zwX6jxevx0RCya0hoiY9hfwh8CNxfuLgYsneZv9kzk9FdvoteleKYfr7DrPhTpP56tXuqpuA5ZKOk7SgcDZwPppLpOZmTXoiX8dGxF7JF0I3AjMA9ZExJZpLpaZmTXoicABEBEbgA1TuMnVkzw9FdvoteleKYfrPLnTvVKOuV7nadMTg+NmZjZz9MoYh5mZzRTTPTo/mS9gPnD+GPI9B3wIuA/4IfClnL4EuCdPLwNOr/IXy/4mT22dS0iPC/8EuC6nvTtv4wNNy9SWvxf4BfA/SQ8P3AH8+1qZ/gh4tFimD/gm8O1cpx8Bg8B1wFtIXYE/A34OPAZsAy4EvgT8IK/jUuBF4Nx6HYGrgEvyPloDvCXP/wmwPG/zH4FNwOb896xiPe8CNufpvwPuAlYATwJ7gD8t8v6gtu2HgKNr++gU4ErgllyG9+b0F4GngF8CXyU9vvh8rvvuqm7AmcDHgWuAy4EbgM81HBvfI/2iwe6crw94HDgrl+ENVXmbjru8jXcDx+R6zi/XX9RzG+n42FEccx/K23w3cEx9/xT1OAH4Auk4WZuX+y/AduD9wEfyfnwOeE9e7iLgx9VnRDo+HgFem/MuyfVcV207p+1l+HFY1eEa0rGxDPg8cCvwNeDOvM+25+09Avwb4KPAr3PdngYGim2+JS/zDOkR1P+dp58iHVufBv573u6vyE9h5vXfD9xMOvafyX+fAP4E+GLen5uBTxT78EM539cZOuY2AX15/lXAZcCu/BlV14hLgReAv87bvR/4cp73S9KDPu/M71+V9/9PgONJ5+Ujeb/fncv6XO34OybX7xsMP5eWAM8Cn69fk2rLX1UuV6RfBBza6Xo42jVztrc45gPn1xPzT5zUp88HTiddqJssy/Pb2gOcLanteNIa4HDgz4GfRcRrI+JfanmOBY6o3kREP+nEgNSanA/siYizIuK7EXE6sBD4MOngp1j2DcVygxFx9QhlOwq4NyK+m9//FvDyPH0pqQt0GeliX27jazm99F7SWNtO4P81lGcYJdVxewppHywDLouINUXW7wF/Q7rIvYS0L+4AflHU7UzSiflERHwoIt4WER8rtlUdG2sj4t6ibP3AkUUZ3hARb5A0L5ftZcD5RVmrwLGIdKF8tqhD6SjSMbYwv18G/G5EfIihwDNs/+Tj6u2kwHEE8BrgYeBA0oXr9oj4W+BbDdu7CPi3eT375eNjsJhf1f/fldsulecSKThflsv9B8CtEfEu0o0BpIvqyryNI/L0AXnebaSbDoDH8/HaTzouAN5MCjwfycfQnmL7/4d0UwAp6Lwf+OP8/sm8vcMiYn1EfDDvz82ki3XlfOD5iPjzpnpmbwLeBnyuYd67SQH2hIi4IKfdk+v5zvz+T0kB7L9GRFVe8n7fSwqww0TENmBHh/I8HBEfGaG8I7kIOHScy86uMQ5Jf0W60O5HugtYSjqBRPpgXgQOztlfAA7K6eXBX38PKeK/pJY2mNerWvqevP2meXNZ034di2D8+7HTsoPM7G7aFxm64I7FRPbhWO1iAheiabSbdI0ojfdYnYjqelRXfXa/yvP3L9Ih9Up8nNSCfzHneQH4w4jYLOnpnPdA0rXpUeClwGJSoB8k3eBdR+o1OAj4fVKr+LlOhZ3JJ88wkvpITfPXku44jmPogHiB9DMmB5OahpBOvL3AT/P7IH0IkHbm3+fpF3OeyK/tOX0/0t3N7mKZH5A+2E4n6e6GtOcYOgh+WUw3eaaYfop810U6aQeLMg7WlqvSK0/X5jXZ02Feue69xfSLDevcU+R/nqF911Smuqj9LctVzxekz7iuLF/VXVVXdWtBOjmbylQvy66GPJDq2rSNuhtq6+y0TFmn6vPdy/B6DTK0T8qy72bocw5SS6fyU/YVDdP17QDUH5Ovfr2hCmTB0OcepP1brrtpnfXjtSlvNT2WYwaGH4+Vaj9tK8pYDxqDDAWNqlxN51Qn9e021fF5hh9rzxflqG5wIfUK/FWefglD5/l/AP4X6TpzSJ4/j9SddWhe7/U5/Zekbu+X5fxHRMQrc/oNEfFS0nVzFanr+cRchpFbMqP1Zc2UF6np9Yk8fQBD/aFV/+ZDpJPpsZw2SOoj3JZ3VOQ81QWzvAg/zFB0XlHMe7GW7ymGTu4Yx2twhHl7a9srX7vGub3xvprKuXuKtl3ft9UF4NcNeV/oUO76Z9xp3ZP16rT90cpTvxi3+YzK93dOoOwP1da3uaFsz07hvhyt/oMMD7pt9n80rGOkfRw0H4f1V/3zG6y9qvTnSeMh5bb2ksYGq/TnSN1kARycr3/fI3VRQ7q5fZwU4Kv1byadr1vzuh7My9+T5w0CV86VMY7f3OVHRHXw7s/QB3AoqZWwl+F3reVd/EvzeoKhH10U8EFyCyUi1hb5y9bCDaQoX70vT5y9RXppEPg+Q3eDTS2VKOaV63yeoTuTqhX1qw7L1m0p1lPPX+2bvbX0qh7lwd2kfnKWd2Dlfi8v4vW7ubK1U971/Zo0+Emx3upEre7Yyn3wcDG9m+EtnrK8LxTTTfWqpz1RS4uGfE0to8otDN//zxbzyv1VnZ8vMLz1UB4nv2ZoH/26Q3q1jmqbx9fKNkhz66aaLstVlhVSdzAMb/VUx2e5/XL+7mK6/FsKhsYtxqqs/0jr3sXwc6lUHffVPikv2k1lrL9vas1BusOvPMzwawek/RV5m1XeA0m9IIMMBQpI403n5PdNrd9BAEnHkcb2riE9yPEEsDuPET1DGld6HWnM81fAf8rzdkXEeR3qAcyirirSBfg/SzpY0mGkJtwhDA3EHU6qb9l3eTDp6YvyBN2PdJI8UOR7X/47KOkYhk6InzJ0Eh9PGjyrLvDlOMc8hndTVQfAfqQfaxxJdXCLoW4wkQbMqnUey9AgcHkwduoye3WHedU2YPh+qra5X1GW+sW+er9fnq7WUz4UUE6X268fh/sV88v6HEAaBC7TD2Fon8PwsajFxfRDpBuD+rb3FO8Had5uGUSreZ32X6X+MEQ578ZaWqfBz3J7hzF0U1Pur4OL9+U2qwBfL4OoPbSQlz+oIV+1rSjW/apa2et/55H2adWFUu3Hsm/+gNq8+g0FpHNwQUP6SMpxnyp/ud+r8+VghgJC/XPcr/g7j6F9Ub8RKPNWxNDxWffSYvooho7byiEM7evKLtL+Fqnr/dk8fTjpYq9a/svy31eRelYOZygYPclQdxWkfaF8kz2PdN789m8qIv1Oh3ok093F1OXuqktJTbJ/IgWSIJ2kVTfKXoa6r/bkD6ZsNlaPhdabls8xdIdS3rm9SHOXwB7G1mRt+9pb20631juedbVt7k9kmyN1e3TqRuh2fSey7nra7lHqVL2auqQGGblbsFPdJrPOwVArrNP2mrY/lV2sI9V/svfNWF6jfdb1ruqqzNtJXVUvkh6z35WX+Yt8TXyGPJ4B3JSXu5MUWHbn+X9HagXdSeq62gv8yYjX2um+2Hc5cByW/x4K9AMnjmGZPuBfWm6nerrhUFI/4T2dtkuH73k0rPOs/MF9pp6f9Mjnt1uWsXG7pLuLqi/0eNLd55Ft91vO/yXy9xXysj8GTiTdUf0M+K2WZf4jUsA9C7id9KTH10bI/xC173bU616bvorU37vPMnn+u8nP5+f3nZ6N30R+vn+k9ZDuIDeTHnn9GWlgcp9tjfUYKZY9Kp/o1fEu0k9R/GX5Geb9+LViudbnR227x5Ba2dcBj7RZtu2rLPtEyz3O7e+zTYa+m3VP/nzPazrmauu5iobvUXShXAK+AvzlZO+LplfP/FZVl6zO/3L2YNKz9z8eKXP+3+YfID3C28Yrge/kv78AtkraPNbtNpTji6R/m/udluUYj0OBmyUdQDr4PgB8uc1+A5B0O6lf9Oj8f1IOJvXJrsl/PxURvxhhFZ3sTzrZdpO+K7F8HOvoBUeSvtB2O+lu7/MR8fTIi4wud5VuAv4H8N8krSDt70OB15O6VdcC7yEdU+V3j1qdH7Xtnku6qfkI8GcTrcco26rOh6rs4y73BOyzTUlL8rzjSd8v+egUlKOu/MzvoPP3zibVrPoeh5mZTb7ZNDhuZmZTwIHDzMxaceAwM7NWHDjMzKwVBw4zM2vFgcPMzFr5/5QWAnldukN+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "\n",
    "_, projs = list(zip(*results))\n",
    "projs = list(projections)\n",
    "movements = [movement[pragmatic_model.projections.index(i)] for i in projs]\n",
    "projs = [i[0] for i in projs]\n",
    "plt = matplotlib.pyplot.bar(projs, movements)\n",
    "plt.figure(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class contains Bayesian models for CONTEXTUALIZED word vectors\n",
    "# S1: fast S1, batched over w, and u (batch of u passed to L0): L0 is implicit in this S1\n",
    "# L1\n",
    "class Contextualized_Pragmatic_Model:\n",
    "  # utterances : list(str). the utterance set U\n",
    "  # projections : list(str). the projection set Q\n",
    "  # vectors : dictionary: key:str,val:[dim vecs] of word embeddings\n",
    "  # sigma1: hyperparameter for L0: variance of L0 posterior\n",
    "  # sigma2: hyperparameter for L1: variance of L1 prior. See paper\n",
    "  # mu2: hyperparameter for L1: the mean of the L1 prior: e.g. \"the man is\" in man is a shark. \n",
    "  def __init__(self,\n",
    "              utterances,\n",
    "              projections,\n",
    "              vectors,\n",
    "              sigma1,\n",
    "              sigma2,\n",
    "              mu2):\n",
    "    \n",
    "    self.utterances=utterances\n",
    "    self.projections=projections\n",
    "    # [NUM U, DIM VECS]\n",
    "    self.utterance_vectors = np.asarray([vectors[u] for u in utterances]) \n",
    "    # [NUM Q, DIM VECS, DIM PROJECTION SUBSPACE]\n",
    "    self.projection_vectors = (np.asarray([np.asarray([vectors[word]/np.linalg.norm(vectors[word]) for word in words]).T for words in self.projections]))\n",
    "    self.vectors=vectors\n",
    "    self.sigma1 = sigma1\n",
    "    self.sigma2 = sigma2\n",
    "    self.mu2 = mu2\n",
    "    \n",
    "    self.dimvecs = vectors[\"the\"].shape[0]\n",
    "    # how many dimensions does each projection have?\n",
    "    self.dimsubspace = self.projection_vectors.shape[-1]\n",
    "    \n",
    "  # u : [DIM VECS]\n",
    "  def L0_Unbatched(self,u):\n",
    "    return self.vecs[u], self.sigma1\n",
    "  \n",
    "  # w : [1,DIM VECS]\n",
    "  # q : [DIM VECS, DIM PROJECTION SUBSPACE]\n",
    "  def S1_Unbatched(self,w,q):\n",
    "    \n",
    "    projection = get_projection(q)\n",
    "    # calculates a term that decreases with the euclidean distance of q(w) to q(u) where q(x) is x projected onto the subspace spanned by q\n",
    "    def utility(w,projection,u):\n",
    "      l0_posterior_mu, l0_posterior_sigma = self.L0_Unbatched(u=u)\n",
    "      projected_w = projection(w)\n",
    "      projected_l0_posterior_mu = projection(l0_posterior_mu)\n",
    "      log_score = multivariate_normal(projected_l0_posterior_mu,l0_posterior_sigma).logpdf(projected_w)\n",
    "      return log_score\n",
    "    \n",
    "    unnormed_log_probs = [utility(w=w,projection=projection,u=u) for u in self.utterance_vectors]\n",
    "    norm = logsumexp(unnormed_log_probs)\n",
    "    return unnormed_log_probs - norm\n",
    "  \n",
    "  # ws: [BATCH w, DIM VECS]\n",
    "  # q: [DIM VECS, DIM PROJECTION SUBSPACE]\n",
    "  def S1_Batched(self, ws,q):\n",
    "\n",
    "    projection = get_projection(q)\n",
    "\n",
    "    # obtain L0 posterior MU and SIGMA\n",
    "    sigma1sq, sigma2sq = self.sigma1 ** 2, self.sigma2 ** 2\n",
    "    inverse_sd = (1/sigma1sq) + (1/sigma2sq)\n",
    "    sigma = np.diag([1/inverse_sd] * self.dimvecs)\n",
    "    inverse_sigma = np.linalg.inv(sigma)\n",
    "    l0_posterior_mu = np.divide(np.add(self.mu1/sigma1sq, self.utterance_vectors/sigma2sq),inverse_sd)\n",
    "\n",
    "    # projections\n",
    "    # [NUM UTTS, DIM VECS]\n",
    "    projected_l0_posterior_mu = projection(l0_posterior_mu)\n",
    "#     print(\"BATCHED\",projected_l0_posterior_mu)\n",
    "    # [BATCH w, DIM VECS]\n",
    "    projected_ws = projection(ws)\n",
    "    \n",
    "    # compute logprob of gaussian\n",
    "    # [BATCH w, NUM UTTS, DIM VECS]\n",
    "    distances = np.expand_dims(projected_ws,1)-np.expand_dims(projected_l0_posterior_mu,0)\n",
    "    # [BATCH w, NUM UTTS, DIM VECS]\n",
    "    rescaled_distances = np.einsum('ij,abi->abj',np.sqrt(inverse_sigma),distances)\n",
    "    # [BATCH w, NUM UTTS]\n",
    "    unnormed_logprobs = -0.5*np.sum(np.square(rescaled_distances),axis=2)\n",
    "    # [BATCH w,1]\n",
    "    norm = np.expand_dims(logsumexp(unnormed_logprobs,axis=-1),-1)\n",
    "    # [BATCH w, NUM UTTS]\n",
    "    return unnormed_logprobs-norm\n",
    "  \n",
    "  def L1(self,u):\n",
    "    #u: [DIM VECS, 1]\n",
    "    #listener_mean: [DIM VECS, 1]\n",
    "    start = -5\n",
    "    stop = 5.01\n",
    "    step = 0.1\n",
    "    # intervals: [NUM INTERVALS]    \n",
    "    intervals = np.arange(start=start,stop=stop,step=step)\n",
    "    num_intervals = int((stop-start)/step)\n",
    "    \n",
    "#     normal = multivariate_normal(mean=self.mu1, cov=[self.sigma1] * self.dimvecs)\n",
    "\n",
    "    \n",
    "    movement = {}\n",
    "    marginal_projection_probs = np.zeros((len(self.projections)))\n",
    "    for i in tqdm(range(len(self.projections))):\n",
    "            \n",
    "      q = self.projection_vectors[i]\n",
    "      # assume q is a vector of unit length\n",
    "      #q: [DIM VECS, 1]\n",
    "      projection = get_projection(q)\n",
    "      # [DIM VECS]\n",
    "      projected_mu1 = projection(self.mu1)\n",
    "      \n",
    "      # [DIM VECS, NUM INTERVALS]\n",
    "      projected_worlds = np.expand_dims(projected_mu1,0) + np.dot(q,np.expand_dims(intervals,0)).T\n",
    "\n",
    "      # [NUM INTERVALS]\n",
    "      speaker_log_likelihood = self.S1_Batched(projected_worlds,q)[:,u]\n",
    "      \n",
    "      # [NUM INTERVALS]\n",
    "      world_log_priors = -1/(self.sigma1**2)*np.square(intervals)\n",
    "      # TODO: draw from real gaussian and see if different\n",
    "#       world_log_priors = np.asarray([normal.logpdf(i) for i in intervals])\n",
    "      \n",
    "      # [NUM INTERVALS]\n",
    "      joint_probs = world_log_priors + speaker_log_likelihood\n",
    "      left,right = np.exp(logsumexp(joint_probs[:num_intervals//2])), np.exp(logsumexp(joint_probs[1+num_intervals//2:]))\n",
    "      movement[i]=right-left\n",
    "      # SCALAR\n",
    "      marginal_projection_prob = logsumexp(joint_probs)      \n",
    "      marginal_projection_probs[i]=marginal_projection_prob\n",
    "    \n",
    "    norm = logsumexp(marginal_projection_probs)\n",
    "    return marginal_projection_probs - norm, movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/9143613 [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 1027072/9143613 [00:00<00:00, 10262704.22B/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 2576384/9143613 [00:00<00:00, 11419003.91B/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 4212736/9143613 [00:00<00:00, 12552672.06B/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 5665792/9143613 [00:00<00:00, 13076179.64B/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 6776832/9143613 [00:00<00:00, 9676817.70B/s] \u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 8267776/9143613 [00:00<00:00, 10815312.51B/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 9143613/9143613 [00:00<00:00, 12529065.16B/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import TransfoXLTokenizer, TransfoXLModel, TransfoXLLMHeadModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "model = TransfoXLModel.from_pretrained('transfo-xl-wt103')\n",
    "model.eval()\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary from wikitext 103)\n",
    "tokenizer = TransfoXLTokenizer.from_pretrained('transfo-xl-wt103')\n",
    "\n",
    "model = TransfoXLLMHeadModel.from_pretrained('transfo-xl-wt103')\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSkQjO-A40K8"
   },
   "source": [
    "projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "\n",
    "def text_to_bertspace(text):\n",
    "    # text_1 = \"The man is a\"\n",
    "    tokenized_text_1 = tokenizer.tokenize(text)\n",
    "    indexed_tokens_1 = tokenizer.convert_tokens_to_ids(tokenized_text_1)\n",
    "    tokens_tensor_1 = torch.tensor([indexed_tokens_1])\n",
    "    # If you have a GPU, put everything on cuda\n",
    "    # tokens_tensor_1 = tokens_tensor_1.to('cuda')\n",
    "    # tokens_tensor_2 = tokens_tensor_2.to('cuda')\n",
    "    # model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Predict hidden states features for each layer\n",
    "        hidden_states_1, mems_1 = model(tokens_tensor_1)\n",
    "        # We can re-use the memory cells in a subsequent call to attend a longer context\n",
    "    #     hidden_states_2, mems_2 = model(tokens_tensor_2, mems=mems_1)\n",
    "    return hidden_states_1.numpy()[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "# tokens_tensor_1 = tokens_tensor_1.to('cuda')\n",
    "# tokens_tensor_2 = tokens_tensor_2.to('cuda')\n",
    "# model.to('cuda')\n",
    "# p(u|c)\n",
    "def text_to_prediction(text):\n",
    "    tokenized_text_1 = tokenizer.tokenize(text)\n",
    "    indexed_tokens_1 = tokenizer.convert_tokens_to_ids(tokenized_text_1)\n",
    "    tokens_tensor_1 = torch.tensor([indexed_tokens_1])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions_1, mems_1 = model(tokens_tensor_1)\n",
    "    \n",
    "    return predictions_1[0, -1, :].numpy()\n",
    "\n",
    "#     predicted_index = torch.argmax(predictions_1[0, -1, :]).item()\n",
    "#     predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.017,  0.137, -0.017, ..., -0.182, -0.042,  0.149], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_prediction(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todos:\n",
    "# simple version: bert utterances, bert mu, bert quds\n",
    "# bert api functions: list to dist(next), list to hidden\n",
    "# new l0\n",
    "# geometry test: \"(the man is a) shark\" along \"vicious\" vs \"(the man is a) fish\" along vicious2\n",
    "# create appropriate bert vectors: for the target phrase, for each target+utt l0 posterior dist, \n",
    "# \n",
    "\n",
    "bert_vecs = {}\n",
    "\n",
    "target = \"man\"\n",
    "source = \"shark\"\n",
    "\n",
    "mu1 = text_to_bertspace(target)\n",
    "\n",
    "# abstract_threshold = 2.5\n",
    "# # concrete_threshold = 3.0\n",
    "\n",
    "# # nouns,adjs = get_words(with_freqs=False)\n",
    "# # nouns = [noun for noun in nouns if noun in vecs]\n",
    "\n",
    "utterances = [\"shark\",\"swimmer\",\"man\"]\n",
    "projections = [[\"swims\"],[\"vicious\"]]\n",
    "\n",
    "# utterance_vecs = to_bert(target+\" \"+source)\n",
    "for i,u in enumerate(utterances):\n",
    "    bert_vecs[u]=text_to_bertspace(target+\" \"+u)\n",
    "    \n",
    "for q in projections:\n",
    "    bert_vecs[q[0]]=text_to_bertspace(q[0])\n",
    "#     bert_vecs[full utterance string]=utterance_vecs[i]\n",
    "\n",
    "bert_vecs[\"the\"]=np.zeros(1024)\n",
    "# projection_vecs = \n",
    "\n",
    "\n",
    "# adjectives = [a for a in adjs if adjs[a] > concrete_threshold and a in vecs]\n",
    "# projections = [a for a in adjs if adjs[a] < abstract_threshold and a in vecs]\n",
    "# projections = sorted(projections,key=lambda x:cosine(vecs[x],vecs[target]))\n",
    "# projections = [[x] for x in projections]\n",
    "\n",
    "# if source in utterances: utterances.remove(source)\n",
    "# utterances = [source]+utterances[:500]\n",
    "# projections = projections[:500]\n",
    "\n",
    "# # projections = [[\"unstable\"],[\"vicious\"]]\n",
    "\n",
    "pragmatic_model = Pragmatic_Model(utterances=utterances,\n",
    "                                  projections=projections,\n",
    "                                  vectors=bert_vecs,\n",
    "                                 sigma1=1.0,\n",
    "                                 sigma2=1.0,\n",
    "                                 mu1=mu1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16  -0.031 -0.127 ... -0.35  -0.224 -0.12 ]\n",
      "[-0.096 -0.08   0.113 ... -0.227 -0.154  0.007]\n"
     ]
    }
   ],
   "source": [
    "print(bert_vecs[\"man\"])\n",
    "print(bert_vecs[\"shark\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fb1895543a48a997e0bb2475330fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline [['swims'], ['vicious']]\n",
      "utterance shark\n",
      "0.502724895061009 ['swims'] 0.46782541688967294\n",
      "0.497275104938991 ['vicious'] 1.0875008543620663\n"
     ]
    }
   ],
   "source": [
    "raw_output, movement = pragmatic_model.L1(u=0)\n",
    "print(\"baseline\",projections[:10])\n",
    "print(\"utterance\",pragmatic_model.utterances[0])\n",
    "results = sorted(list(zip(np.exp(raw_output),projections)),key=lambda x: x[0],reverse=True)\n",
    "\n",
    "for i,(prob,q) in enumerate(results):\n",
    "    print(prob,q,movement[pragmatic_model.projections.index(q)])\n",
    "    if i > 20: break\n",
    "# print(movement[pragmatic_model.projections.index([\"pure\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vector_space_pragmatics.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
